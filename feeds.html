
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="Security alerts and cybersecurity news feeds">
        <meta name="keywords" content="cybersecurity news, security alerts, vulnerability feeds, threat intelligence">
        <meta name="author" content="dotne1">
        <meta property="og:title" content="Security Feeds - dotne1's Cybersecurity Portfolio">
        <meta property="og:description" content="Stay updated with the latest cybersecurity news and alerts">
        <meta property="og:type" content="website">
        <title>Security Feeds - dotne1's Cybersecurity Portfolio</title>
        <link rel="stylesheet" href="styles.css">
        <link rel="icon" type="image/x-icon" href="/favicon.ico">
    </head>
    <body>
        <nav class="navbar">
            <div class="nav-links">
                <a href="index.html" class="nav-link">Home</a>
                <a href="about-me.html" class="nav-link">About Me</a>
                <a href="projects.html" class="nav-link">Projects</a>
                <a href="resume.html" class="nav-link">Resume</a>
                <a href="feeds.html" class="nav-link">Feeds</a>
            </div>
        </nav>

        <div class="container" role="main">
            <h1 class="main-header">Security Feeds</h1>
            <div class="search-bar">
                <input type="text" id="searchInput" placeholder="Search CVEs..." onkeyup="searchCVEs()">
            </div>
            <div class="feed-preview" id="cveFeed">
                <div class="feed-header">Latest Vulnerabilities</div>
    
                <div class="cve-entry" data-cve-id="CVE-2025-40300" data-description="in the linux kernel, the following vulnerability has been resolved:

x86/vmscape: add conditional ibpb mitigation

vmscape is a vulnerability that exploits insufficient branch predictor
isolation between a guest and a userspace hypervisor (like qemu). existing
mitigations already protect kernel/kvm from a malicious guest. userspace
can additionally be protected by flushing the branch predictors after a
vmexit.

since it is the userspace that consumes the poisoned branch predictors,
conditionally issue an ibpb after a vmexit and before returning to
userspace. workloads that frequently switch between hypervisor and
userspace will incur the most overhead from the new ibpb.

this new ibpb is not integrated with the existing ibpb sites. for
instance, a task can use the existing speculation control prctl() to
get an ibpb at context switch time. with this implementation, the
ibpb is doubled up: one at context switch and another before running
userspace.

the intent is to integrate and optimize these cases post-embargo.

[ dhansen: elaborate on suboptimal ibpb solution ]">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-40300" target="_blank">CVE-2025-40300</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:45 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

x86/vmscape: Add conditional IBPB mitigation

VMSCAPE is a vulnerability that exploits insufficient branch predictor
isolation between a guest and a userspace hypervisor (like QEMU). Existing
mitigations already protect kernel/KVM from a malicious guest. Userspace
can additionally be protected by flushing the branch predictors after a
VMexit.

Since it is the userspace that consumes the poisoned branch predictors,
conditionally issue an IBPB after a VMexit and before returning to
userspace. Workloads that frequently switch between hypervisor and
userspace will incur the most overhead from the new IBPB.

This new IBPB is not integrated with the existing IBPB sites. For
instance, a task can use the existing speculation control prctl() to
get an IBPB at context switch time. With this implementation, the
IBPB is doubled up: one at context switch and another before running
userspace.

The intent is to integrate and optimize these cases post-embargo.

[ dhansen: elaborate on suboptimal IBPB solution ]</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39791" data-description="in the linux kernel, the following vulnerability has been resolved:

dm: dm-crypt: do not partially accept write bios with zoned targets

read and write operations issued to a dm-crypt target may be split
according to the dm-crypt internal limits defined by the max_read_size
and max_write_size module parameters (default is 128 kb). the intent is
to improve processing time of large bios by splitting them into smaller
operations that can be parallelized on different cpus.

for zoned dm-crypt targets, this bio splitting is still done but without
the parallel execution to ensure that the issuing order of write
operations to the underlying devices remains sequential. however, the
splitting itself causes other problems:

1) since dm-crypt relies on the block layer zone write plugging to
   handle zone append emulation using regular write operations, the
   reminder of a split write bio will always be plugged into the target
   zone write plugged. once the on-going write bio finishes, this
   reminder bio is unplugged and issued from the zone write plug work.
   if this reminder bio itself needs to be split, the reminder will be
   re-issued and plugged again, but that causes a call to a
   blk_queue_enter(), which may block if a queue freeze operation was
   initiated. this results in a deadlock as dm submission still holds
   bios that the queue freeze side is waiting for.

2) dm-crypt relies on the emulation done by the block layer using
   regular write operations for processing zone append operations. this
   still requires to properly return the written sector as the bio
   sector of the original bio. however, this can be done correctly only
   and only if there is a single clone bio used for processing the
   original zone append operation issued by the user. if the size of a
   zone append operation is larger than dm-crypt max_write_size, then
   the orginal bio will be split and processed as a chain of regular
   write operations. such chaining result in an incorrect written sector
   being returned to the zone append issuer using the original bio
   sector.  this in turn results in file system data corruptions using
   xfs or btrfs.

fix this by modifying get_max_request_size() to always return the size
of the bio to avoid it being split with dm_accpet_partial_bio() in
crypt_map(). get_max_request_size() is renamed to
get_max_request_sectors() to clarify the unit of the value returned
and its interface is changed to take a struct dm_target pointer and a
pointer to the struct bio being processed. in addition to this change,
to ensure that crypt_alloc_buffer() works correctly, set the dm-crypt
device max_hw_sectors limit to be at most
bio_max_vecs << page_sectors_shift (1 mb with a 4kb page architecture).
this forces dm core to split write bios before passing them to
crypt_map(), and thus guaranteeing that dm-crypt can always accept an
entire write bio without needing to split it.

this change does not have any effect on the read path of dm-crypt. read
operations can still be split and the bio fragments processed in
parallel. there is also no impact on the performance of the write path
given that all zone write bios were already processed inline instead of
in parallel.

this change also does not affect in any way regular dm-crypt block
devices.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39791" target="_blank">CVE-2025-39791</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:45 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

dm: dm-crypt: Do not partially accept write BIOs with zoned targets

Read and write operations issued to a dm-crypt target may be split
according to the dm-crypt internal limits defined by the max_read_size
and max_write_size module parameters (default is 128 KB). The intent is
to improve processing time of large BIOs by splitting them into smaller
operations that can be parallelized on different CPUs.

For zoned dm-crypt targets, this BIO splitting is still done but without
the parallel execution to ensure that the issuing order of write
operations to the underlying devices remains sequential. However, the
splitting itself causes other problems:

1) Since dm-crypt relies on the block layer zone write plugging to
   handle zone append emulation using regular write operations, the
   reminder of a split write BIO will always be plugged into the target
   zone write plugged. Once the on-going write BIO finishes, this
   reminder BIO is unplugged and issued from the zone write plug work.
   If this reminder BIO itself needs to be split, the reminder will be
   re-issued and plugged again, but that causes a call to a
   blk_queue_enter(), which may block if a queue freeze operation was
   initiated. This results in a deadlock as DM submission still holds
   BIOs that the queue freeze side is waiting for.

2) dm-crypt relies on the emulation done by the block layer using
   regular write operations for processing zone append operations. This
   still requires to properly return the written sector as the BIO
   sector of the original BIO. However, this can be done correctly only
   and only if there is a single clone BIO used for processing the
   original zone append operation issued by the user. If the size of a
   zone append operation is larger than dm-crypt max_write_size, then
   the orginal BIO will be split and processed as a chain of regular
   write operations. Such chaining result in an incorrect written sector
   being returned to the zone append issuer using the original BIO
   sector.  This in turn results in file system data corruptions using
   xfs or btrfs.

Fix this by modifying get_max_request_size() to always return the size
of the BIO to avoid it being split with dm_accpet_partial_bio() in
crypt_map(). get_max_request_size() is renamed to
get_max_request_sectors() to clarify the unit of the value returned
and its interface is changed to take a struct dm_target pointer and a
pointer to the struct bio being processed. In addition to this change,
to ensure that crypt_alloc_buffer() works correctly, set the dm-crypt
device max_hw_sectors limit to be at most
BIO_MAX_VECS << PAGE_SECTORS_SHIFT (1 MB with a 4KB page architecture).
This forces DM core to split write BIOs before passing them to
crypt_map(), and thus guaranteeing that dm-crypt can always accept an
entire write BIO without needing to split it.

This change does not have any effect on the read path of dm-crypt. Read
operations can still be split and the BIO fragments processed in
parallel. There is also no impact on the performance of the write path
given that all zone write BIOs were already processed inline instead of
in parallel.

This change also does not affect in any way regular dm-crypt block
devices.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39790" data-description="in the linux kernel, the following vulnerability has been resolved:

bus: mhi: host: detect events pointing to unexpected tres

when a remote device sends a completion event to the host, it contains a
pointer to the consumed tre. the host uses this pointer to process all of
the tres between it and the host's local copy of the ring's read pointer.
this works when processing completion for chained transactions, but can
lead to nasty results if the device sends an event for a single-element
transaction with a read pointer that is multiple elements ahead of the
host's read pointer.

for instance, if the host accesses an event ring while the device is
updating it, the pointer inside of the event might still point to an old
tre. if the host uses the channel's xfer_cb() to directly free the buffer
pointed to by the tre, the buffer will be double-freed.

this behavior was observed on an ep that used upstream ep stack without
'commit 6f18d174b73d ("bus: mhi: ep: update read pointer only after buffer
is written")'. where the device updated the events ring pointer before
updating the event contents, so it left a window where the host was able to
access the stale data the event pointed to, before the device had the
chance to update them. the usual pattern was that the host received an
event pointing to a tre that is not immediately after the last processed
one, so it got treated as if it was a chained transaction, processing all
of the tres in between the two read pointers.

this commit aims to harden the host by ensuring transactions where the
event points to a tre that isn't local_rp + 1 are chained.

[mani: added stable tag and reworded commit message]">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39790" target="_blank">CVE-2025-39790</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:45 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

bus: mhi: host: Detect events pointing to unexpected TREs

When a remote device sends a completion event to the host, it contains a
pointer to the consumed TRE. The host uses this pointer to process all of
the TREs between it and the host's local copy of the ring's read pointer.
This works when processing completion for chained transactions, but can
lead to nasty results if the device sends an event for a single-element
transaction with a read pointer that is multiple elements ahead of the
host's read pointer.

For instance, if the host accesses an event ring while the device is
updating it, the pointer inside of the event might still point to an old
TRE. If the host uses the channel's xfer_cb() to directly free the buffer
pointed to by the TRE, the buffer will be double-freed.

This behavior was observed on an ep that used upstream EP stack without
'commit 6f18d174b73d ("bus: mhi: ep: Update read pointer only after buffer
is written")'. Where the device updated the events ring pointer before
updating the event contents, so it left a window where the host was able to
access the stale data the event pointed to, before the device had the
chance to update them. The usual pattern was that the host received an
event pointing to a TRE that is not immediately after the last processed
one, so it got treated as if it was a chained transaction, processing all
of the TREs in between the two read pointers.

This commit aims to harden the host by ensuring transactions where the
event points to a TRE that isn't local_rp + 1 are chained.

[mani: added stable tag and reworded commit message]</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39789" data-description="in the linux kernel, the following vulnerability has been resolved:

crypto: x86/aegis - add missing error checks

the skcipher_walk functions can allocate memory and can fail, so
checking for errors is necessary.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39789" target="_blank">CVE-2025-39789</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:45 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

crypto: x86/aegis - Add missing error checks

The skcipher_walk functions can allocate memory and can fail, so
checking for errors is necessary.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39788" data-description="in the linux kernel, the following vulnerability has been resolved:

scsi: ufs: exynos: fix programming of hci_utrl_nexus_type

on google gs101, the number of utp transfer request slots (nutrs) is 32,
and in this case the driver ends up programming the utrl_nexus_type
incorrectly as 0.

this is because the left hand side of the shift is 1, which is of type
int, i.e. 31 bits wide. shifting by more than that width results in
undefined behaviour.

fix this by switching to the bit() macro, which applies correct type
casting as required. this ensures the correct value is written to
utrl_nexus_type (0xffffffff on gs101), and it also fixes a ubsan shift
warning:

    ubsan: shift-out-of-bounds in drivers/ufs/host/ufs-exynos.c:1113:21
    shift exponent 32 is too large for 32-bit type 'int'

for consistency, apply the same change to the nutmrs / utmrl_nexus_type
write.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39788" target="_blank">CVE-2025-39788</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:45 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

scsi: ufs: exynos: Fix programming of HCI_UTRL_NEXUS_TYPE

On Google gs101, the number of UTP transfer request slots (nutrs) is 32,
and in this case the driver ends up programming the UTRL_NEXUS_TYPE
incorrectly as 0.

This is because the left hand side of the shift is 1, which is of type
int, i.e. 31 bits wide. Shifting by more than that width results in
undefined behaviour.

Fix this by switching to the BIT() macro, which applies correct type
casting as required. This ensures the correct value is written to
UTRL_NEXUS_TYPE (0xffffffff on gs101), and it also fixes a UBSAN shift
warning:

    UBSAN: shift-out-of-bounds in drivers/ufs/host/ufs-exynos.c:1113:21
    shift exponent 32 is too large for 32-bit type 'int'

For consistency, apply the same change to the nutmrs / UTMRL_NEXUS_TYPE
write.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39787" data-description="in the linux kernel, the following vulnerability has been resolved:

soc: qcom: mdt_loader: ensure we don't read past the elf header

when the mdt loader is used in remoteproc, the elf header is sanitized
beforehand, but that's not necessary the case for other clients.

validate the size of the firmware buffer to ensure that we don't read
past the end as we iterate over the header. e_phentsize and e_shentsize
are validated as well, to ensure that the assumptions about step size in
the traversal are valid.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39787" target="_blank">CVE-2025-39787</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

soc: qcom: mdt_loader: Ensure we don't read past the ELF header

When the MDT loader is used in remoteproc, the ELF header is sanitized
beforehand, but that's not necessary the case for other clients.

Validate the size of the firmware buffer to ensure that we don't read
past the end as we iterate over the header. e_phentsize and e_shentsize
are validated as well, to ensure that the assumptions about step size in
the traversal are valid.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39786" data-description="in the linux kernel, the following vulnerability has been resolved:

iio: adc: ad7173: fix channels index for syscalib_mode

fix the index used to look up the channel when accessing the
syscalib_mode attribute. the address field is a 0-based index (same
as scan_index) that it used to access the channel in the
ad7173_channels array throughout the driver. the channels field, on
the other hand, may not match the address field depending on the
channel configuration specified in the device tree and could result
in an out-of-bounds access.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39786" target="_blank">CVE-2025-39786</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

iio: adc: ad7173: fix channels index for syscalib_mode

Fix the index used to look up the channel when accessing the
syscalib_mode attribute. The address field is a 0-based index (same
as scan_index) that it used to access the channel in the
ad7173_channels array throughout the driver. The channels field, on
the other hand, may not match the address field depending on the
channel configuration specified in the device tree and could result
in an out-of-bounds access.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39785" data-description="in the linux kernel, the following vulnerability has been resolved:

drm/hisilicon/hibmc: fix irq_request()'s irq name variable is local

the local variable is passed in request_irq (), and there will be use
after free problem, which will make request_irq failed. using the global
irq name instead of it to fix.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39785" target="_blank">CVE-2025-39785</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

drm/hisilicon/hibmc: fix irq_request()'s irq name variable is local

The local variable is passed in request_irq (), and there will be use
after free problem, which will make request_irq failed. Using the global
irq name instead of it to fix.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39784" data-description="in the linux kernel, the following vulnerability has been resolved:

pci: fix link speed calculation on retrain failure

when pcie_failed_link_retrain() fails to retrain, it tries to revert to the
previous link speed.  however it calculates that speed from the link
control 2 register without masking out non-speed bits first.

pcie_lnkctl2_tls2speed() converts such incorrect values to
pci_speed_unknown (0xff), which in turn causes a warn splat in
pcie_set_target_speed():

  pci 0000:00:01.1: [1022:14ed] type 01 class 0x060400 pcie root port
  pci 0000:00:01.1: broken device, retraining non-functional downstream link at 2.5gt/s
  pci 0000:00:01.1: retraining failed
  warning: cpu: 1 pid: 1 at drivers/pci/pcie/bwctrl.c:168 pcie_set_target_speed
  rdx: 0000000000000001 rsi: 00000000000000ff rdi: ffff9acd82efa000
  pcie_failed_link_retrain
  pci_device_add
  pci_scan_single_device

mask out the non-speed bits in pcie_lnkctl2_tls2speed() and
pcie_lnkcap_sls2speed() so they don't incorrectly return pci_speed_unknown.

[bhelgaas: commit log, add details from https://lore.kernel.org/r/1c92ef6bcb314ee6977839b46b393282e4f52e74.1750684771.git.lukas@wunner.de]">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39784" target="_blank">CVE-2025-39784</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

PCI: Fix link speed calculation on retrain failure

When pcie_failed_link_retrain() fails to retrain, it tries to revert to the
previous link speed.  However it calculates that speed from the Link
Control 2 register without masking out non-speed bits first.

PCIE_LNKCTL2_TLS2SPEED() converts such incorrect values to
PCI_SPEED_UNKNOWN (0xff), which in turn causes a WARN splat in
pcie_set_target_speed():

  pci 0000:00:01.1: [1022:14ed] type 01 class 0x060400 PCIe Root Port
  pci 0000:00:01.1: broken device, retraining non-functional downstream link at 2.5GT/s
  pci 0000:00:01.1: retraining failed
  WARNING: CPU: 1 PID: 1 at drivers/pci/pcie/bwctrl.c:168 pcie_set_target_speed
  RDX: 0000000000000001 RSI: 00000000000000ff RDI: ffff9acd82efa000
  pcie_failed_link_retrain
  pci_device_add
  pci_scan_single_device

Mask out the non-speed bits in PCIE_LNKCTL2_TLS2SPEED() and
PCIE_LNKCAP_SLS2SPEED() so they don't incorrectly return PCI_SPEED_UNKNOWN.

[bhelgaas: commit log, add details from https://lore.kernel.org/r/1c92ef6bcb314ee6977839b46b393282e4f52e74.1750684771.git.lukas@wunner.de]</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39783" data-description="in the linux kernel, the following vulnerability has been resolved:

pci: endpoint: fix configfs group list head handling

doing a list_del() on the epf_group field of struct pci_epf_driver in
pci_epf_remove_cfs() is not correct as this field is a list head, not
a list entry. this list_del() call triggers a kasan warning when an
endpoint function driver which has a configfs attribute group is torn
down:

==================================================================
bug: kasan: slab-use-after-free in pci_epf_remove_cfs+0x17c/0x198
write of size 8 at addr ffff00010f4a0d80 by task rmmod/319

cpu: 3 uid: 0 pid: 319 comm: rmmod not tainted 6.16.0-rc2 #1 none
hardware name: radxa rock 5b (dt)
call trace:
show_stack+0x2c/0x84 (c)
dump_stack_lvl+0x70/0x98
print_report+0x17c/0x538
kasan_report+0xb8/0x190
__asan_report_store8_noabort+0x20/0x2c
pci_epf_remove_cfs+0x17c/0x198
pci_epf_unregister_driver+0x18/0x30
nvmet_pci_epf_cleanup_module+0x24/0x30 [nvmet_pci_epf]
__arm64_sys_delete_module+0x264/0x424
invoke_syscall+0x70/0x260
el0_svc_common.constprop.0+0xac/0x230
do_el0_svc+0x40/0x58
el0_svc+0x48/0xdc
el0t_64_sync_handler+0x10c/0x138
el0t_64_sync+0x198/0x19c
...

remove this incorrect list_del() call from pci_epf_remove_cfs().">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39783" target="_blank">CVE-2025-39783</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

PCI: endpoint: Fix configfs group list head handling

Doing a list_del() on the epf_group field of struct pci_epf_driver in
pci_epf_remove_cfs() is not correct as this field is a list head, not
a list entry. This list_del() call triggers a KASAN warning when an
endpoint function driver which has a configfs attribute group is torn
down:

==================================================================
BUG: KASAN: slab-use-after-free in pci_epf_remove_cfs+0x17c/0x198
Write of size 8 at addr ffff00010f4a0d80 by task rmmod/319

CPU: 3 UID: 0 PID: 319 Comm: rmmod Not tainted 6.16.0-rc2 #1 NONE
Hardware name: Radxa ROCK 5B (DT)
Call trace:
show_stack+0x2c/0x84 (C)
dump_stack_lvl+0x70/0x98
print_report+0x17c/0x538
kasan_report+0xb8/0x190
__asan_report_store8_noabort+0x20/0x2c
pci_epf_remove_cfs+0x17c/0x198
pci_epf_unregister_driver+0x18/0x30
nvmet_pci_epf_cleanup_module+0x24/0x30 [nvmet_pci_epf]
__arm64_sys_delete_module+0x264/0x424
invoke_syscall+0x70/0x260
el0_svc_common.constprop.0+0xac/0x230
do_el0_svc+0x40/0x58
el0_svc+0x48/0xdc
el0t_64_sync_handler+0x10c/0x138
el0t_64_sync+0x198/0x19c
...

Remove this incorrect list_del() call from pci_epf_remove_cfs().</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39782" data-description="in the linux kernel, the following vulnerability has been resolved:

jbd2: prevent softlockup in jbd2_log_do_checkpoint()

both jbd2_log_do_checkpoint() and jbd2_journal_shrink_checkpoint_list()
periodically release j_list_lock after processing a batch of buffers to
avoid long hold times on the j_list_lock. however, since both functions
contend for j_list_lock, the combined time spent waiting and processing
can be significant.

jbd2_journal_shrink_checkpoint_list() explicitly calls cond_resched() when
need_resched() is true to avoid softlockups during prolonged operations.
but jbd2_log_do_checkpoint() only exits its loop when need_resched() is
true, relying on potentially sleeping functions like __flush_batch() or
wait_on_buffer() to trigger rescheduling. if those functions do not sleep,
the kernel may hit a softlockup.

watchdog: bug: soft lockup - cpu#3 stuck for 156s! [kworker/u129:2:373]
cpu: 3 pid: 373 comm: kworker/u129:2 kdump: loaded not tainted 6.6.0+ #10
hardware name: huawei taishan 2280 /bc11spcd, bios 1.27 06/13/2017
workqueue: writeback wb_workfn (flush-7:2)
pstate: 20000005 (nzcv daif -pan -uao -tco -dit -ssbs btype=--)
pc : native_queued_spin_lock_slowpath+0x358/0x418
lr : jbd2_log_do_checkpoint+0x31c/0x438 [jbd2]
call trace:
 native_queued_spin_lock_slowpath+0x358/0x418
 jbd2_log_do_checkpoint+0x31c/0x438 [jbd2]
 __jbd2_log_wait_for_space+0xfc/0x2f8 [jbd2]
 add_transaction_credits+0x3bc/0x418 [jbd2]
 start_this_handle+0xf8/0x560 [jbd2]
 jbd2__journal_start+0x118/0x228 [jbd2]
 __ext4_journal_start_sb+0x110/0x188 [ext4]
 ext4_do_writepages+0x3dc/0x740 [ext4]
 ext4_writepages+0xa4/0x190 [ext4]
 do_writepages+0x94/0x228
 __writeback_single_inode+0x48/0x318
 writeback_sb_inodes+0x204/0x590
 __writeback_inodes_wb+0x54/0xf8
 wb_writeback+0x2cc/0x3d8
 wb_do_writeback+0x2e0/0x2f8
 wb_workfn+0x80/0x2a8
 process_one_work+0x178/0x3e8
 worker_thread+0x234/0x3b8
 kthread+0xf0/0x108
 ret_from_fork+0x10/0x20

so explicitly call cond_resched() in jbd2_log_do_checkpoint() to avoid
softlockup.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39782" target="_blank">CVE-2025-39782</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

jbd2: prevent softlockup in jbd2_log_do_checkpoint()

Both jbd2_log_do_checkpoint() and jbd2_journal_shrink_checkpoint_list()
periodically release j_list_lock after processing a batch of buffers to
avoid long hold times on the j_list_lock. However, since both functions
contend for j_list_lock, the combined time spent waiting and processing
can be significant.

jbd2_journal_shrink_checkpoint_list() explicitly calls cond_resched() when
need_resched() is true to avoid softlockups during prolonged operations.
But jbd2_log_do_checkpoint() only exits its loop when need_resched() is
true, relying on potentially sleeping functions like __flush_batch() or
wait_on_buffer() to trigger rescheduling. If those functions do not sleep,
the kernel may hit a softlockup.

watchdog: BUG: soft lockup - CPU#3 stuck for 156s! [kworker/u129:2:373]
CPU: 3 PID: 373 Comm: kworker/u129:2 Kdump: loaded Not tainted 6.6.0+ #10
Hardware name: Huawei TaiShan 2280 /BC11SPCD, BIOS 1.27 06/13/2017
Workqueue: writeback wb_workfn (flush-7:2)
pstate: 20000005 (nzCv daif -PAN -UAO -TCO -DIT -SSBS BTYPE=--)
pc : native_queued_spin_lock_slowpath+0x358/0x418
lr : jbd2_log_do_checkpoint+0x31c/0x438 [jbd2]
Call trace:
 native_queued_spin_lock_slowpath+0x358/0x418
 jbd2_log_do_checkpoint+0x31c/0x438 [jbd2]
 __jbd2_log_wait_for_space+0xfc/0x2f8 [jbd2]
 add_transaction_credits+0x3bc/0x418 [jbd2]
 start_this_handle+0xf8/0x560 [jbd2]
 jbd2__journal_start+0x118/0x228 [jbd2]
 __ext4_journal_start_sb+0x110/0x188 [ext4]
 ext4_do_writepages+0x3dc/0x740 [ext4]
 ext4_writepages+0xa4/0x190 [ext4]
 do_writepages+0x94/0x228
 __writeback_single_inode+0x48/0x318
 writeback_sb_inodes+0x204/0x590
 __writeback_inodes_wb+0x54/0xf8
 wb_writeback+0x2cc/0x3d8
 wb_do_writeback+0x2e0/0x2f8
 wb_workfn+0x80/0x2a8
 process_one_work+0x178/0x3e8
 worker_thread+0x234/0x3b8
 kthread+0xf0/0x108
 ret_from_fork+0x10/0x20

So explicitly call cond_resched() in jbd2_log_do_checkpoint() to avoid
softlockup.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39781" data-description="in the linux kernel, the following vulnerability has been resolved:

parisc: drop warn_on_once() from flush_cache_vmap

i have observed warning to occassionally trigger.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39781" target="_blank">CVE-2025-39781</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

parisc: Drop WARN_ON_ONCE() from flush_cache_vmap

I have observed warning to occassionally trigger.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39780" data-description="in the linux kernel, the following vulnerability has been resolved:

sched/ext: fix invalid task state transitions on class switch

when enabling a sched_ext scheduler, we may trigger invalid task state
transitions, resulting in warnings like the following (which can be
easily reproduced by running the hotplug selftest in a loop):

 sched_ext: invalid task state transition 0 -> 3 for fish[770]
 warning: cpu: 18 pid: 787 at kernel/sched/ext.c:3862 scx_set_task_state+0x7c/0xc0
 ...
 rip: 0010:scx_set_task_state+0x7c/0xc0
 ...
 call trace:
  <task>
  scx_enable_task+0x11f/0x2e0
  switching_to_scx+0x24/0x110
  scx_enable.isra.0+0xd14/0x13d0
  bpf_struct_ops_link_create+0x136/0x1a0
  __sys_bpf+0x1edd/0x2c30
  __x64_sys_bpf+0x21/0x30
  do_syscall_64+0xbb/0x370
  entry_syscall_64_after_hwframe+0x77/0x7f

this happens because we skip initialization for tasks that are already
dead (with their usage counter set to zero), but we don't exclude them
during the scheduling class transition phase.

fix this by also skipping dead tasks during class swiching, preventing
invalid task state transitions.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39780" target="_blank">CVE-2025-39780</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:43 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

sched/ext: Fix invalid task state transitions on class switch

When enabling a sched_ext scheduler, we may trigger invalid task state
transitions, resulting in warnings like the following (which can be
easily reproduced by running the hotplug selftest in a loop):

 sched_ext: Invalid task state transition 0 -> 3 for fish[770]
 WARNING: CPU: 18 PID: 787 at kernel/sched/ext.c:3862 scx_set_task_state+0x7c/0xc0
 ...
 RIP: 0010:scx_set_task_state+0x7c/0xc0
 ...
 Call Trace:
  <TASK>
  scx_enable_task+0x11f/0x2e0
  switching_to_scx+0x24/0x110
  scx_enable.isra.0+0xd14/0x13d0
  bpf_struct_ops_link_create+0x136/0x1a0
  __sys_bpf+0x1edd/0x2c30
  __x64_sys_bpf+0x21/0x30
  do_syscall_64+0xbb/0x370
  entry_SYSCALL_64_after_hwframe+0x77/0x7f

This happens because we skip initialization for tasks that are already
dead (with their usage counter set to zero), but we don't exclude them
during the scheduling class transition phase.

Fix this by also skipping dead tasks during class swiching, preventing
invalid task state transitions.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39779" data-description="in the linux kernel, the following vulnerability has been resolved:

btrfs: subpage: keep towrite tag until folio is cleaned

btrfs_subpage_set_writeback() calls folio_start_writeback() the first time
a folio is written back, and it also clears the pagecache_tag_towrite tag
even if there are still dirty blocks in the folio. this can break ordering
guarantees, such as those required by btrfs_wait_ordered_extents().

that ordering breakage leads to a real failure. for example, running
generic/464 on a zoned setup will hit the following assert. this happens
because the broken ordering fails to flush existing dirty pages before the
file size is truncated.

  assertion failed: !list_empty(&ordered->list) :: 0, in fs/btrfs/zoned.c:1899
  ------------[ cut here ]------------
  kernel bug at fs/btrfs/zoned.c:1899!
  oops: invalid opcode: 0000 [#1] smp nopti
  cpu: 2 uid: 0 pid: 1906169 comm: kworker/u130:2 kdump: loaded not tainted 6.16.0-rc6-btrfs-zns+ #554 preempt(voluntary)
  hardware name: supermicro super server/h12ssl-nt, bios 2.0 02/22/2021
  workqueue: btrfs-endio-write btrfs_work_helper [btrfs]
  rip: 0010:btrfs_finish_ordered_zoned.cold+0x50/0x52 [btrfs]
  rsp: 0018:ffffc9002efdbd60 eflags: 00010246
  rax: 000000000000004c rbx: ffff88811923c4e0 rcx: 0000000000000000
  rdx: 0000000000000000 rsi: ffffffff827e38b1 rdi: 00000000ffffffff
  rbp: ffff88810005d000 r08: 00000000ffffdfff r09: ffffffff831051c8
  r10: ffffffff83055220 r11: 0000000000000000 r12: ffff8881c2458c00
  r13: ffff88811923c540 r14: ffff88811923c5e8 r15: ffff8881c1bd9680
  fs:  0000000000000000(0000) gs:ffff88a04acd0000(0000) knlgs:0000000000000000
  cs:  0010 ds: 0000 es: 0000 cr0: 0000000080050033
  cr2: 00007f907c7a918c cr3: 0000000004024000 cr4: 0000000000350ef0
  call trace:
   <task>
   ? srso_return_thunk+0x5/0x5f
   btrfs_finish_ordered_io+0x4a/0x60 [btrfs]
   btrfs_work_helper+0xf9/0x490 [btrfs]
   process_one_work+0x204/0x590
   ? srso_return_thunk+0x5/0x5f
   worker_thread+0x1d6/0x3d0
   ? __pfx_worker_thread+0x10/0x10
   kthread+0x118/0x230
   ? __pfx_kthread+0x10/0x10
   ret_from_fork+0x205/0x260
   ? __pfx_kthread+0x10/0x10
   ret_from_fork_asm+0x1a/0x30
   </task>

consider process a calling writepages() with wb_sync_none. in zoned mode or
for compressed writes, it locks several folios for delalloc and starts
writing them out. let's call the last locked folio folio x. suppose the
write range only partially covers folio x, leaving some pages dirty.
process a calls btrfs_subpage_set_writeback() when building a bio. this
function call clears the towrite tag of folio x, whose size = 8k and
the block size = 4k. it is following state.

   0     4k    8k
   |/////|/////|  (flag: dirty, tag: dirty)
   <-----> process a will write this range.

now suppose process b concurrently calls writepages() with wb_sync_all. it
calls tag_pages_for_writeback() to tag dirty folios with
pagecache_tag_towrite. since folio x is still dirty, it gets tagged. then,
b collects tagged folios using filemap_get_folios_tag() and must wait for
folio x to be written before returning from writepages().

   0     4k    8k
   |/////|/////|  (flag: dirty, tag: dirty|towrite)

however, between tagging and collecting, process a may call
btrfs_subpage_set_writeback() and clear folio x's towrite tag.
   0     4k    8k
   |     |/////|  (flag: dirty|writeback, tag: dirty)

as a result, process b won't see folio x in its batch, and returns without
waiting for it. this breaks the wb_sync_all ordering requirement.

fix this by using btrfs_subpage_set_writeback_keepwrite(), which retains
the towrite tag. we now manually clear the tag only after the folio becomes
clean, via the xas operation.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39779" target="_blank">CVE-2025-39779</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:43 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

btrfs: subpage: keep TOWRITE tag until folio is cleaned

btrfs_subpage_set_writeback() calls folio_start_writeback() the first time
a folio is written back, and it also clears the PAGECACHE_TAG_TOWRITE tag
even if there are still dirty blocks in the folio. This can break ordering
guarantees, such as those required by btrfs_wait_ordered_extents().

That ordering breakage leads to a real failure. For example, running
generic/464 on a zoned setup will hit the following ASSERT. This happens
because the broken ordering fails to flush existing dirty pages before the
file size is truncated.

  assertion failed: !list_empty(&ordered->list) :: 0, in fs/btrfs/zoned.c:1899
  ------------[ cut here ]------------
  kernel BUG at fs/btrfs/zoned.c:1899!
  Oops: invalid opcode: 0000 [#1] SMP NOPTI
  CPU: 2 UID: 0 PID: 1906169 Comm: kworker/u130:2 Kdump: loaded Not tainted 6.16.0-rc6-BTRFS-ZNS+ #554 PREEMPT(voluntary)
  Hardware name: Supermicro Super Server/H12SSL-NT, BIOS 2.0 02/22/2021
  Workqueue: btrfs-endio-write btrfs_work_helper [btrfs]
  RIP: 0010:btrfs_finish_ordered_zoned.cold+0x50/0x52 [btrfs]
  RSP: 0018:ffffc9002efdbd60 EFLAGS: 00010246
  RAX: 000000000000004c RBX: ffff88811923c4e0 RCX: 0000000000000000
  RDX: 0000000000000000 RSI: ffffffff827e38b1 RDI: 00000000ffffffff
  RBP: ffff88810005d000 R08: 00000000ffffdfff R09: ffffffff831051c8
  R10: ffffffff83055220 R11: 0000000000000000 R12: ffff8881c2458c00
  R13: ffff88811923c540 R14: ffff88811923c5e8 R15: ffff8881c1bd9680
  FS:  0000000000000000(0000) GS:ffff88a04acd0000(0000) knlGS:0000000000000000
  CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
  CR2: 00007f907c7a918c CR3: 0000000004024000 CR4: 0000000000350ef0
  Call Trace:
   <TASK>
   ? srso_return_thunk+0x5/0x5f
   btrfs_finish_ordered_io+0x4a/0x60 [btrfs]
   btrfs_work_helper+0xf9/0x490 [btrfs]
   process_one_work+0x204/0x590
   ? srso_return_thunk+0x5/0x5f
   worker_thread+0x1d6/0x3d0
   ? __pfx_worker_thread+0x10/0x10
   kthread+0x118/0x230
   ? __pfx_kthread+0x10/0x10
   ret_from_fork+0x205/0x260
   ? __pfx_kthread+0x10/0x10
   ret_from_fork_asm+0x1a/0x30
   </TASK>

Consider process A calling writepages() with WB_SYNC_NONE. In zoned mode or
for compressed writes, it locks several folios for delalloc and starts
writing them out. Let's call the last locked folio folio X. Suppose the
write range only partially covers folio X, leaving some pages dirty.
Process A calls btrfs_subpage_set_writeback() when building a bio. This
function call clears the TOWRITE tag of folio X, whose size = 8K and
the block size = 4K. It is following state.

   0     4K    8K
   |/////|/////|  (flag: DIRTY, tag: DIRTY)
   <-----> Process A will write this range.

Now suppose process B concurrently calls writepages() with WB_SYNC_ALL. It
calls tag_pages_for_writeback() to tag dirty folios with
PAGECACHE_TAG_TOWRITE. Since folio X is still dirty, it gets tagged. Then,
B collects tagged folios using filemap_get_folios_tag() and must wait for
folio X to be written before returning from writepages().

   0     4K    8K
   |/////|/////|  (flag: DIRTY, tag: DIRTY|TOWRITE)

However, between tagging and collecting, process A may call
btrfs_subpage_set_writeback() and clear folio X's TOWRITE tag.
   0     4K    8K
   |     |/////|  (flag: DIRTY|WRITEBACK, tag: DIRTY)

As a result, process B won't see folio X in its batch, and returns without
waiting for it. This breaks the WB_SYNC_ALL ordering requirement.

Fix this by using btrfs_subpage_set_writeback_keepwrite(), which retains
the TOWRITE tag. We now manually clear the tag only after the folio becomes
clean, via the xas operation.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39777" data-description="in the linux kernel, the following vulnerability has been resolved:

crypto: acomp - fix cfi failure due to type punning

to avoid a crash when control flow integrity is enabled, make the
workspace ("stream") free function use a consistent type, and call it
through a function pointer that has that same type.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39777" target="_blank">CVE-2025-39777</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:43 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

crypto: acomp - Fix CFI failure due to type punning

To avoid a crash when control flow integrity is enabled, make the
workspace ("stream") free function use a consistent type, and call it
through a function pointer that has that same type.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39776" data-description="in the linux kernel, the following vulnerability has been resolved:

mm/debug_vm_pgtable: clear page table entries at destroy_args()

the mm/debug_vm_pagetable test allocates manually page table entries for
the tests it runs, using also its manually allocated mm_struct.  that in
itself is ok, but when it exits, at destroy_args() it fails to clear those
entries with the *_clear functions.

the problem is that leaves stale entries.  if another process allocates an
mm_struct with a pgd at the same address, it may end up running into the
stale entry.  this is happening in practice on a debug kernel with
config_debug_vm_pgtable=y, for example this is the output with some extra
debugging i added (it prints a warning trace if pgtables_bytes goes
negative, in addition to the warning at check_mm() function):

[    2.539353] debug_vm_pgtable: [get_random_vaddr         ]: random_vaddr is 0x7ea247140000
[    2.539366] kmem_cache info
[    2.539374] kmem_cachep 0x000000002ce82385 - freelist 0x0000000000000000 - offset 0x508
[    2.539447] debug_vm_pgtable: [init_args                ]: args->mm is 0x000000002267cc9e
(...)
[    2.552800] warning: cpu: 5 pid: 116 at include/linux/mm.h:2841 free_pud_range+0x8bc/0x8d0
[    2.552816] modules linked in:
[    2.552843] cpu: 5 uid: 0 pid: 116 comm: modprobe not tainted 6.12.0-105.debug_vm2.el10.ppc64le+debug #1 voluntary
[    2.552859] hardware name: ibm,9009-41a power9 (architected) 0x4e0202 0xf000005 of:ibm,fw910.00 (vl910_062) hv:phyp pseries
[    2.552872] nip:  c0000000007eef3c lr: c0000000007eef30 ctr: c0000000003d8c90
[    2.552885] regs: c0000000622e73b0 trap: 0700   not tainted  (6.12.0-105.debug_vm2.el10.ppc64le+debug)
[    2.552899] msr:  800000000282b033 <sf,vec,vsx,ee,fp,me,ir,dr,ri,le>  cr: 24002822  xer: 0000000a
[    2.552954] cfar: c0000000008f03f0 irqmask: 0
[    2.552954] gpr00: c0000000007eef30 c0000000622e7650 c000000002b1ac00 0000000000000001
[    2.552954] gpr04: 0000000000000008 0000000000000000 c0000000007eef30 ffffffffffffffff
[    2.552954] gpr08: 00000000ffff00f5 0000000000000001 0000000000000048 0000000000004000
[    2.552954] gpr12: 00000003fa440000 c000000017ffa300 c0000000051d9f80 ffffffffffffffdb
[    2.552954] gpr16: 0000000000000000 0000000000000008 000000000000000a 60000000000000e0
[    2.552954] gpr20: 4080000000000000 c0000000113af038 00007fffcf130000 0000700000000000
[    2.552954] gpr24: c000000062a6a000 0000000000000001 8000000062a68000 0000000000000001
[    2.552954] gpr28: 000000000000000a c000000062ebc600 0000000000002000 c000000062ebc760
[    2.553170] nip [c0000000007eef3c] free_pud_range+0x8bc/0x8d0
[    2.553185] lr [c0000000007eef30] free_pud_range+0x8b0/0x8d0
[    2.553199] call trace:
[    2.553207] [c0000000622e7650] [c0000000007eef30] free_pud_range+0x8b0/0x8d0 (unreliable)
[    2.553229] [c0000000622e7750] [c0000000007f40b4] free_pgd_range+0x284/0x3b0
[    2.553248] [c0000000622e7800] [c0000000007f4630] free_pgtables+0x450/0x570
[    2.553274] [c0000000622e78e0] [c0000000008161c0] exit_mmap+0x250/0x650
[    2.553292] [c0000000622e7a30] [c0000000001b95b8] __mmput+0x98/0x290
[    2.558344] [c0000000622e7a80] [c0000000001d1018] exit_mm+0x118/0x1b0
[    2.558361] [c0000000622e7ac0] [c0000000001d141c] do_exit+0x2ec/0x870
[    2.558376] [c0000000622e7b60] [c0000000001d1ca8] do_group_exit+0x88/0x150
[    2.558391] [c0000000622e7bb0] [c0000000001d1db8] sys_exit_group+0x48/0x50
[    2.558407] [c0000000622e7be0] [c00000000003d810] system_call_exception+0x1e0/0x4c0
[    2.558423] [c0000000622e7e50] [c00000000000d05c] system_call_vectored_common+0x15c/0x2ec
(...)
[    2.558892] ---[ end trace 0000000000000000 ]---
[    2.559022] bug: bad rss-counter state mm:000000002267cc9e type:mm_anonpages val:1
[    2.559037] bug: non-zero pgtables_bytes on freeing mm: -6144

here the modprobe process ended up with an allocated mm_struct from the
mm_struct slab that was used before by the debug_vm_pgtable test.  that is
not a problem, since the mm_stru
---truncated---">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39776" target="_blank">CVE-2025-39776</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:43 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

mm/debug_vm_pgtable: clear page table entries at destroy_args()

The mm/debug_vm_pagetable test allocates manually page table entries for
the tests it runs, using also its manually allocated mm_struct.  That in
itself is ok, but when it exits, at destroy_args() it fails to clear those
entries with the *_clear functions.

The problem is that leaves stale entries.  If another process allocates an
mm_struct with a pgd at the same address, it may end up running into the
stale entry.  This is happening in practice on a debug kernel with
CONFIG_DEBUG_VM_PGTABLE=y, for example this is the output with some extra
debugging I added (it prints a warning trace if pgtables_bytes goes
negative, in addition to the warning at check_mm() function):

[    2.539353] debug_vm_pgtable: [get_random_vaddr         ]: random_vaddr is 0x7ea247140000
[    2.539366] kmem_cache info
[    2.539374] kmem_cachep 0x000000002ce82385 - freelist 0x0000000000000000 - offset 0x508
[    2.539447] debug_vm_pgtable: [init_args                ]: args->mm is 0x000000002267cc9e
(...)
[    2.552800] WARNING: CPU: 5 PID: 116 at include/linux/mm.h:2841 free_pud_range+0x8bc/0x8d0
[    2.552816] Modules linked in:
[    2.552843] CPU: 5 UID: 0 PID: 116 Comm: modprobe Not tainted 6.12.0-105.debug_vm2.el10.ppc64le+debug #1 VOLUNTARY
[    2.552859] Hardware name: IBM,9009-41A POWER9 (architected) 0x4e0202 0xf000005 of:IBM,FW910.00 (VL910_062) hv:phyp pSeries
[    2.552872] NIP:  c0000000007eef3c LR: c0000000007eef30 CTR: c0000000003d8c90
[    2.552885] REGS: c0000000622e73b0 TRAP: 0700   Not tainted  (6.12.0-105.debug_vm2.el10.ppc64le+debug)
[    2.552899] MSR:  800000000282b033 <SF,VEC,VSX,EE,FP,ME,IR,DR,RI,LE>  CR: 24002822  XER: 0000000a
[    2.552954] CFAR: c0000000008f03f0 IRQMASK: 0
[    2.552954] GPR00: c0000000007eef30 c0000000622e7650 c000000002b1ac00 0000000000000001
[    2.552954] GPR04: 0000000000000008 0000000000000000 c0000000007eef30 ffffffffffffffff
[    2.552954] GPR08: 00000000ffff00f5 0000000000000001 0000000000000048 0000000000004000
[    2.552954] GPR12: 00000003fa440000 c000000017ffa300 c0000000051d9f80 ffffffffffffffdb
[    2.552954] GPR16: 0000000000000000 0000000000000008 000000000000000a 60000000000000e0
[    2.552954] GPR20: 4080000000000000 c0000000113af038 00007fffcf130000 0000700000000000
[    2.552954] GPR24: c000000062a6a000 0000000000000001 8000000062a68000 0000000000000001
[    2.552954] GPR28: 000000000000000a c000000062ebc600 0000000000002000 c000000062ebc760
[    2.553170] NIP [c0000000007eef3c] free_pud_range+0x8bc/0x8d0
[    2.553185] LR [c0000000007eef30] free_pud_range+0x8b0/0x8d0
[    2.553199] Call Trace:
[    2.553207] [c0000000622e7650] [c0000000007eef30] free_pud_range+0x8b0/0x8d0 (unreliable)
[    2.553229] [c0000000622e7750] [c0000000007f40b4] free_pgd_range+0x284/0x3b0
[    2.553248] [c0000000622e7800] [c0000000007f4630] free_pgtables+0x450/0x570
[    2.553274] [c0000000622e78e0] [c0000000008161c0] exit_mmap+0x250/0x650
[    2.553292] [c0000000622e7a30] [c0000000001b95b8] __mmput+0x98/0x290
[    2.558344] [c0000000622e7a80] [c0000000001d1018] exit_mm+0x118/0x1b0
[    2.558361] [c0000000622e7ac0] [c0000000001d141c] do_exit+0x2ec/0x870
[    2.558376] [c0000000622e7b60] [c0000000001d1ca8] do_group_exit+0x88/0x150
[    2.558391] [c0000000622e7bb0] [c0000000001d1db8] sys_exit_group+0x48/0x50
[    2.558407] [c0000000622e7be0] [c00000000003d810] system_call_exception+0x1e0/0x4c0
[    2.558423] [c0000000622e7e50] [c00000000000d05c] system_call_vectored_common+0x15c/0x2ec
(...)
[    2.558892] ---[ end trace 0000000000000000 ]---
[    2.559022] BUG: Bad rss-counter state mm:000000002267cc9e type:MM_ANONPAGES val:1
[    2.559037] BUG: non-zero pgtables_bytes on freeing mm: -6144

Here the modprobe process ended up with an allocated mm_struct from the
mm_struct slab that was used before by the debug_vm_pgtable test.  That is
not a problem, since the mm_stru
---truncated---</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39775" data-description="in the linux kernel, the following vulnerability has been resolved:

mm/mremap: fix warn with uffd that has remap events disabled

registering userfaultd on a vma that spans at least one pmd and then
mremap()'ing that vma can trigger a warn when recovering from a failed
page table move due to a page table allocation error.

the code ends up doing the right thing (recurse, avoiding moving actual
page tables), but triggering that warn is unpleasant:

warning: cpu: 2 pid: 6133 at mm/mremap.c:357 move_normal_pmd mm/mremap.c:357 [inline]
warning: cpu: 2 pid: 6133 at mm/mremap.c:357 move_pgt_entry mm/mremap.c:595 [inline]
warning: cpu: 2 pid: 6133 at mm/mremap.c:357 move_page_tables+0x3832/0x44a0 mm/mremap.c:852
modules linked in:
cpu: 2 uid: 0 pid: 6133 comm: syz.0.19 not tainted 6.17.0-rc1-syzkaller-00004-g53e760d89498 #0 preempt(full)
hardware name: qemu standard pc (q35 + ich9, 2009), bios 1.16.3-debian-1.16.3-2~bpo12+1 04/01/2014
rip: 0010:move_normal_pmd mm/mremap.c:357 [inline]
rip: 0010:move_pgt_entry mm/mremap.c:595 [inline]
rip: 0010:move_page_tables+0x3832/0x44a0 mm/mremap.c:852
code: ...
rsp: 0018:ffffc900037a76d8 eflags: 00010293
rax: 0000000000000000 rbx: 0000000032930007 rcx: ffffffff820c6645
rdx: ffff88802e56a440 rsi: ffffffff820c7201 rdi: 0000000000000007
rbp: ffff888037728fc0 r08: 0000000000000007 r09: 0000000000000000
r10: 0000000032930007 r11: 0000000000000000 r12: 0000000000000000
r13: ffffc900037a79a8 r14: 0000000000000001 r15: dffffc0000000000
fs:  000055556316a500(0000) gs:ffff8880d68bc000(0000) knlgs:0000000000000000
cs:  0010 ds: 0000 es: 0000 cr0: 0000000080050033
cr2: 0000001b30863fff cr3: 0000000050171000 cr4: 0000000000352ef0
call trace:
 <task>
 copy_vma_and_data+0x468/0x790 mm/mremap.c:1215
 move_vma+0x548/0x1780 mm/mremap.c:1282
 mremap_to+0x1b7/0x450 mm/mremap.c:1406
 do_mremap+0xfad/0x1f80 mm/mremap.c:1921
 __do_sys_mremap+0x119/0x170 mm/mremap.c:1977
 do_syscall_x64 arch/x86/entry/syscall_64.c:63 [inline]
 do_syscall_64+0xcd/0x4c0 arch/x86/entry/syscall_64.c:94
 entry_syscall_64_after_hwframe+0x77/0x7f
rip: 0033:0x7f00d0b8ebe9
code: ...
rsp: 002b:00007ffe5ea5ee98 eflags: 00000246 orig_rax: 0000000000000019
rax: ffffffffffffffda rbx: 00007f00d0db5fa0 rcx: 00007f00d0b8ebe9
rdx: 0000000000400000 rsi: 0000000000c00000 rdi: 0000200000000000
rbp: 00007ffe5ea5eef0 r08: 0000200000c00000 r09: 0000000000000000
r10: 0000000000000003 r11: 0000000000000246 r12: 0000000000000002
r13: 00007f00d0db5fa0 r14: 00007f00d0db5fa0 r15: 0000000000000005
 </task>

the underlying issue is that we recurse during the original page table
move, but not during the recovery move.

fix it by checking for both vmas and performing the check before the
pmd_none() sanity check.

add a new helper where we perform+document that check for the pmd and pud
level.

thanks to harry for bisecting.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39775" target="_blank">CVE-2025-39775</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:43 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

mm/mremap: fix WARN with uffd that has remap events disabled

Registering userfaultd on a VMA that spans at least one PMD and then
mremap()'ing that VMA can trigger a WARN when recovering from a failed
page table move due to a page table allocation error.

The code ends up doing the right thing (recurse, avoiding moving actual
page tables), but triggering that WARN is unpleasant:

WARNING: CPU: 2 PID: 6133 at mm/mremap.c:357 move_normal_pmd mm/mremap.c:357 [inline]
WARNING: CPU: 2 PID: 6133 at mm/mremap.c:357 move_pgt_entry mm/mremap.c:595 [inline]
WARNING: CPU: 2 PID: 6133 at mm/mremap.c:357 move_page_tables+0x3832/0x44a0 mm/mremap.c:852
Modules linked in:
CPU: 2 UID: 0 PID: 6133 Comm: syz.0.19 Not tainted 6.17.0-rc1-syzkaller-00004-g53e760d89498 #0 PREEMPT(full)
Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 1.16.3-debian-1.16.3-2~bpo12+1 04/01/2014
RIP: 0010:move_normal_pmd mm/mremap.c:357 [inline]
RIP: 0010:move_pgt_entry mm/mremap.c:595 [inline]
RIP: 0010:move_page_tables+0x3832/0x44a0 mm/mremap.c:852
Code: ...
RSP: 0018:ffffc900037a76d8 EFLAGS: 00010293
RAX: 0000000000000000 RBX: 0000000032930007 RCX: ffffffff820c6645
RDX: ffff88802e56a440 RSI: ffffffff820c7201 RDI: 0000000000000007
RBP: ffff888037728fc0 R08: 0000000000000007 R09: 0000000000000000
R10: 0000000032930007 R11: 0000000000000000 R12: 0000000000000000
R13: ffffc900037a79a8 R14: 0000000000000001 R15: dffffc0000000000
FS:  000055556316a500(0000) GS:ffff8880d68bc000(0000) knlGS:0000000000000000
CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
CR2: 0000001b30863fff CR3: 0000000050171000 CR4: 0000000000352ef0
Call Trace:
 <TASK>
 copy_vma_and_data+0x468/0x790 mm/mremap.c:1215
 move_vma+0x548/0x1780 mm/mremap.c:1282
 mremap_to+0x1b7/0x450 mm/mremap.c:1406
 do_mremap+0xfad/0x1f80 mm/mremap.c:1921
 __do_sys_mremap+0x119/0x170 mm/mremap.c:1977
 do_syscall_x64 arch/x86/entry/syscall_64.c:63 [inline]
 do_syscall_64+0xcd/0x4c0 arch/x86/entry/syscall_64.c:94
 entry_SYSCALL_64_after_hwframe+0x77/0x7f
RIP: 0033:0x7f00d0b8ebe9
Code: ...
RSP: 002b:00007ffe5ea5ee98 EFLAGS: 00000246 ORIG_RAX: 0000000000000019
RAX: ffffffffffffffda RBX: 00007f00d0db5fa0 RCX: 00007f00d0b8ebe9
RDX: 0000000000400000 RSI: 0000000000c00000 RDI: 0000200000000000
RBP: 00007ffe5ea5eef0 R08: 0000200000c00000 R09: 0000000000000000
R10: 0000000000000003 R11: 0000000000000246 R12: 0000000000000002
R13: 00007f00d0db5fa0 R14: 00007f00d0db5fa0 R15: 0000000000000005
 </TASK>

The underlying issue is that we recurse during the original page table
move, but not during the recovery move.

Fix it by checking for both VMAs and performing the check before the
pmd_none() sanity check.

Add a new helper where we perform+document that check for the PMD and PUD
level.

Thanks to Harry for bisecting.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39774" data-description="in the linux kernel, the following vulnerability has been resolved:

iio: adc: rzg2l_adc: set driver data before enabling runtime pm

when stress-testing the system by repeatedly unbinding and binding the adc
device in a loop, and the adc is a supplier for another device (e.g., a
thermal hardware block that reads temperature through the adc), it may
happen that the adc device is runtime-resumed immediately after runtime pm
is enabled, triggered by its consumer. at this point, since drvdata is not
yet set and the driver's runtime pm callbacks rely on it, a crash can
occur. to avoid this, set drvdata just after it was allocated.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39774" target="_blank">CVE-2025-39774</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:43 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

iio: adc: rzg2l_adc: Set driver data before enabling runtime PM

When stress-testing the system by repeatedly unbinding and binding the ADC
device in a loop, and the ADC is a supplier for another device (e.g., a
thermal hardware block that reads temperature through the ADC), it may
happen that the ADC device is runtime-resumed immediately after runtime PM
is enabled, triggered by its consumer. At this point, since drvdata is not
yet set and the driver's runtime PM callbacks rely on it, a crash can
occur. To avoid this, set drvdata just after it was allocated.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39773" data-description="in the linux kernel, the following vulnerability has been resolved:

net: bridge: fix soft lockup in br_multicast_query_expired()

when set multicast_query_interval to a large value, the local variable
'time' in br_multicast_send_query() may overflow. if the time is smaller
than jiffies, the timer will expire immediately, and then call mod_timer()
again, which creates a loop and may trigger the following soft lockup
issue.

  watchdog: bug: soft lockup - cpu#1 stuck for 221s! [rb_consumer:66]
  cpu: 1 uid: 0 pid: 66 comm: rb_consumer not tainted 6.16.0+ #259 preempt(none)
  call trace:
   <irq>
   __netdev_alloc_skb+0x2e/0x3a0
   br_ip6_multicast_alloc_query+0x212/0x1b70
   __br_multicast_send_query+0x376/0xac0
   br_multicast_send_query+0x299/0x510
   br_multicast_query_expired.constprop.0+0x16d/0x1b0
   call_timer_fn+0x3b/0x2a0
   __run_timers+0x619/0x950
   run_timer_softirq+0x11c/0x220
   handle_softirqs+0x18e/0x560
   __irq_exit_rcu+0x158/0x1a0
   sysvec_apic_timer_interrupt+0x76/0x90
   </irq>

this issue can be reproduced with:
  ip link add br0 type bridge
  echo 1 > /sys/class/net/br0/bridge/multicast_querier
  echo 0xffffffffffffffff >
  	/sys/class/net/br0/bridge/multicast_query_interval
  ip link set dev br0 up

the multicast_startup_query_interval can also cause this issue. similar to
the commit 99b40610956a ("net: bridge: mcast: add and enforce query
interval minimum"), add check for the query interval maximum to fix this
issue.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39773" target="_blank">CVE-2025-39773</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:43 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

net: bridge: fix soft lockup in br_multicast_query_expired()

When set multicast_query_interval to a large value, the local variable
'time' in br_multicast_send_query() may overflow. If the time is smaller
than jiffies, the timer will expire immediately, and then call mod_timer()
again, which creates a loop and may trigger the following soft lockup
issue.

  watchdog: BUG: soft lockup - CPU#1 stuck for 221s! [rb_consumer:66]
  CPU: 1 UID: 0 PID: 66 Comm: rb_consumer Not tainted 6.16.0+ #259 PREEMPT(none)
  Call Trace:
   <IRQ>
   __netdev_alloc_skb+0x2e/0x3a0
   br_ip6_multicast_alloc_query+0x212/0x1b70
   __br_multicast_send_query+0x376/0xac0
   br_multicast_send_query+0x299/0x510
   br_multicast_query_expired.constprop.0+0x16d/0x1b0
   call_timer_fn+0x3b/0x2a0
   __run_timers+0x619/0x950
   run_timer_softirq+0x11c/0x220
   handle_softirqs+0x18e/0x560
   __irq_exit_rcu+0x158/0x1a0
   sysvec_apic_timer_interrupt+0x76/0x90
   </IRQ>

This issue can be reproduced with:
  ip link add br0 type bridge
  echo 1 > /sys/class/net/br0/bridge/multicast_querier
  echo 0xffffffffffffffff >
  	/sys/class/net/br0/bridge/multicast_query_interval
  ip link set dev br0 up

The multicast_startup_query_interval can also cause this issue. Similar to
the commit 99b40610956a ("net: bridge: mcast: add and enforce query
interval minimum"), add check for the query interval maximum to fix this
issue.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39772" data-description="in the linux kernel, the following vulnerability has been resolved:

drm/hisilicon/hibmc: fix the hibmc loaded failed bug

when hibmc loaded failed, the driver use hibmc_unload to free the
resource, but the mutexes in mode.config are not init, which will
access an null pointer. just change goto statement to return, because
hibnc_hw_init() doesn't need to free anything.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39772" target="_blank">CVE-2025-39772</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:42 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

drm/hisilicon/hibmc: fix the hibmc loaded failed bug

When hibmc loaded failed, the driver use hibmc_unload to free the
resource, but the mutexes in mode.config are not init, which will
access an NULL pointer. Just change goto statement to return, because
hibnc_hw_init() doesn't need to free anything.</p>
                </div>
        
            </div>
        </div>

        <footer class="footer">
            <p>© 2025 dotne1 - Cybersecurity Portfolio</p>
        </footer>

        <script>
            function searchCVEs() {
                const input = document.getElementById('searchInput').value.toLowerCase();
                const cveEntries = document.getElementsByClassName('cve-entry');
                for (let i = 0; i < cveEntries.length; i++) {
                    const cveId = cveEntries[i].getAttribute('data-cve-id').toLowerCase();
                    const description = cveEntries[i].getAttribute('data-description');
                    if (cveId.includes(input) || description.includes(input)) {
                        cveEntries[i].style.display = '';
                    } else {
                        cveEntries[i].style.display = 'none';
                    }
                }
            }
        </script>
    </body>
    </html>
    