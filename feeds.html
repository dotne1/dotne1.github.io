
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="Security alerts and cybersecurity news feeds">
        <meta name="keywords" content="cybersecurity news, security alerts, vulnerability feeds, threat intelligence">
        <meta name="author" content="dotne1">
        <meta property="og:title" content="Security Feeds - dotne1's Cybersecurity Portfolio">
        <meta property="og:description" content="Stay updated with the latest cybersecurity news and alerts">
        <meta property="og:type" content="website">
        <title>Security Feeds - dotne1's Cybersecurity Portfolio</title>
        <link rel="stylesheet" href="styles.css">
        <link rel="icon" type="image/x-icon" href="/favicon.ico">
    </head>
    <body>
        <nav class="navbar">
            <div class="nav-links">
                <a href="index.html" class="nav-link">Home</a>
                <a href="about-me.html" class="nav-link">About Me</a>
                <a href="projects.html" class="nav-link">Projects</a>
                <a href="resume.html" class="nav-link">Resume</a>
                <a href="feeds.html" class="nav-link">Feeds</a>
            </div>
        </nav>

        <div class="container" role="main">
            <h1 class="main-header">Security Feeds</h1>
            <div class="search-bar">
                <input type="text" id="searchInput" placeholder="Search CVEs..." onkeyup="searchCVEs()">
            </div>
            <div class="feed-preview" id="cveFeed">
                <div class="feed-header">Latest Vulnerabilities</div>
    
                <div class="cve-entry" data-cve-id="CVE-2025-59047" data-description="matrix-sdk-base is the base component to build a matrix client library. in matrix-sdk-base before 0.14.1, calling the `roommember::normalized_power_level()` method can cause a panic if a room member has a power level of `int::min`. the issue is fixed in matrix-sdk-base 0.14.1. the affected method isn’t used internally, so avoiding calling `roommember::normalized_power_level()` prevents the panic.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-59047" target="_blank">CVE-2025-59047</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 13:15:35 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>matrix-sdk-base is the base component to build a Matrix client library. In matrix-sdk-base before 0.14.1, calling the `RoomMember::normalized_power_level()` method can cause a panic if a room member has a power level of `Int::Min`. The issue is fixed in matrix-sdk-base 0.14.1. The affected method isn’t used internally, so avoiding calling `RoomMember::normalized_power_level()` prevents the panic.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-58364" data-description="openprinting cups is an open source printing system for linux and other unix-like operating systems. in versions 2.4.12 and earlier, an unsafe deserialization and validation of printer attributes causes null dereference in the libcups library. this is a remote dos vulnerability available in local subnet in default configurations. it can cause the cups & cups-browsed to crash, on all the machines in local network who are listening for printers (so by default for all regular linux machines). on systems where the vulnerability cve-2024-47176 (cups-filters 1.x/cups-browsed 2.x vulnerability) was not fixed, and the firewall on the machine does not reject incoming communication to ipp port, and the machine is set to be available to public internet, attack vector "network" is possible. the current versions of cups and cups-browsed projects have the attack vector "adjacent" in their default configurations. version 2.4.13 contains a patch for cve-2025-58364.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-58364" target="_blank">CVE-2025-58364</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 13:15:35 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">MEDIUM</span></p>
                    <p><span class="feed-label">CVSS Score:</span> 6.5</p>
                    <p>OpenPrinting CUPS is an open source printing system for Linux and other Unix-like operating systems. In versions 2.4.12 and earlier, an unsafe deserialization and validation of printer attributes causes null dereference in the libcups library. This is a remote DoS vulnerability available in local subnet in default configurations. It can cause the cups & cups-browsed to crash, on all the machines in local network who are listening for printers (so by default for all regular linux machines). On systems where the vulnerability CVE-2024-47176 (cups-filters 1.x/cups-browsed 2.x vulnerability) was not fixed, and the firewall on the machine does not reject incoming communication to IPP port, and the machine is set to be available to public internet, attack vector "Network" is possible. The current versions of CUPS and cups-browsed projects have the attack vector "Adjacent" in their default configurations. Version 2.4.13 contains a patch for CVE-2025-58364.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-58065" data-description="flask-appbuilder is an application development framework. prior to version 4.8.1, when flask-appbuilder is configured to use oauth, ldap, or other non-database authentication methods, the password reset endpoint remains registered and accessible, despite not being displayed in the user interface. this allows an enabled user to reset their password and be able to create jwt tokens even after the user is disabled on the authentication provider. users should upgrade to flask-appbuilder version 4.8.1 or later to receive a fix. if immediate upgrade is not possible, manually disable password reset routes in the application configuration; implement additional access controls at the web server or proxy level to block access to the reset my password url; and/or monitor for suspicious password reset attempts from disabled accounts.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-58065" target="_blank">CVE-2025-58065</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 13:15:35 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">MEDIUM</span></p>
                    <p><span class="feed-label">CVSS Score:</span> 6.5</p>
                    <p>Flask-AppBuilder is an application development framework. Prior to version 4.8.1, when Flask-AppBuilder is configured to use OAuth, LDAP, or other non-database authentication methods, the password reset endpoint remains registered and accessible, despite not being displayed in the user interface. This allows an enabled user to reset their password and be able to create JWT tokens even after the user is disabled on the authentication provider. Users should upgrade to Flask-AppBuilder version 4.8.1 or later to receive a fix. If immediate upgrade is not possible, manually disable password reset routes in the application configuration; implement additional access controls at the web server or proxy level to block access to the reset my password URL; and/or monitor for suspicious password reset attempts from disabled accounts.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-58060" data-description="openprinting cups is an open source printing system for linux and other unix-like operating systems. in versions 2.4.12 and earlier, when the `authtype` is set to anything but `basic`, if the request contains an `authorization: basic ...` header, the password is not checked. this results in authentication bypass. any configuration that allows an `authtype` that is not `basic` is affected. version 2.4.13 fixes the issue.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-58060" target="_blank">CVE-2025-58060</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 13:15:34 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-online">HIGH</span></p>
                    <p><span class="feed-label">CVSS Score:</span> 8.0</p>
                    <p>OpenPrinting CUPS is an open source printing system for Linux and other Unix-like operating systems. In versions 2.4.12 and earlier, when the `AuthType` is set to anything but `Basic`, if the request contains an `Authorization: Basic ...` header, the password is not checked. This results in authentication bypass. Any configuration that allows an `AuthType` that is not `Basic` is affected. Version 2.4.13 fixes the issue.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-43790" data-description="insecure direct object reference (idor) vulnerability in liferay portal 7.4.0 through 7.4.3.124, and liferay dxp 2024.q2.0 through 2024.q2.6, 2024.q1.1 through 2024.q1.12 and 7.4 ga through update 92 allows remote authenticated users to from one virtual instance to access, create, edit, relate data/object entries/definitions to an object in a different virtual instance.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-43790" target="_blank">CVE-2025-43790</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 13:15:34 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>Insecure Direct Object Reference (IDOR) vulnerability in Liferay Portal 7.4.0 through 7.4.3.124, and Liferay DXP 2024.Q2.0 through 2024.Q2.6, 2024.Q1.1 through 2024.Q1.12 and 7.4 GA through update 92 allows remote authenticated users to from one virtual instance to access, create, edit, relate data/object entries/definitions to an object in a different virtual instance.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-43782" data-description="insecure direct object reference (idor) vulnerability in liferay portal 7.4.0 through 7.4.3.124, and liferay dxp 2024.q2.0 through 2024.q2.7, 2024.q1.1 through 2024.q1.12, and 7.4 ga through update 92 allows remote authenticated users to access a workflow definition by name via the api">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-43782" target="_blank">CVE-2025-43782</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 13:15:33 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>Insecure Direct Object Reference (IDOR) vulnerability in Liferay Portal 7.4.0 through 7.4.3.124, and Liferay DXP 2024.Q2.0 through 2024.Q2.7, 2024.Q1.1 through 2024.Q1.12, and 7.4 GA through update 92 allows remote authenticated users to access a workflow definition by name via the API</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-40300" data-description="in the linux kernel, the following vulnerability has been resolved:

x86/vmscape: add conditional ibpb mitigation

vmscape is a vulnerability that exploits insufficient branch predictor
isolation between a guest and a userspace hypervisor (like qemu). existing
mitigations already protect kernel/kvm from a malicious guest. userspace
can additionally be protected by flushing the branch predictors after a
vmexit.

since it is the userspace that consumes the poisoned branch predictors,
conditionally issue an ibpb after a vmexit and before returning to
userspace. workloads that frequently switch between hypervisor and
userspace will incur the most overhead from the new ibpb.

this new ibpb is not integrated with the existing ibpb sites. for
instance, a task can use the existing speculation control prctl() to
get an ibpb at context switch time. with this implementation, the
ibpb is doubled up: one at context switch and another before running
userspace.

the intent is to integrate and optimize these cases post-embargo.

[ dhansen: elaborate on suboptimal ibpb solution ]">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-40300" target="_blank">CVE-2025-40300</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:45 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

x86/vmscape: Add conditional IBPB mitigation

VMSCAPE is a vulnerability that exploits insufficient branch predictor
isolation between a guest and a userspace hypervisor (like QEMU). Existing
mitigations already protect kernel/KVM from a malicious guest. Userspace
can additionally be protected by flushing the branch predictors after a
VMexit.

Since it is the userspace that consumes the poisoned branch predictors,
conditionally issue an IBPB after a VMexit and before returning to
userspace. Workloads that frequently switch between hypervisor and
userspace will incur the most overhead from the new IBPB.

This new IBPB is not integrated with the existing IBPB sites. For
instance, a task can use the existing speculation control prctl() to
get an IBPB at context switch time. With this implementation, the
IBPB is doubled up: one at context switch and another before running
userspace.

The intent is to integrate and optimize these cases post-embargo.

[ dhansen: elaborate on suboptimal IBPB solution ]</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39791" data-description="in the linux kernel, the following vulnerability has been resolved:

dm: dm-crypt: do not partially accept write bios with zoned targets

read and write operations issued to a dm-crypt target may be split
according to the dm-crypt internal limits defined by the max_read_size
and max_write_size module parameters (default is 128 kb). the intent is
to improve processing time of large bios by splitting them into smaller
operations that can be parallelized on different cpus.

for zoned dm-crypt targets, this bio splitting is still done but without
the parallel execution to ensure that the issuing order of write
operations to the underlying devices remains sequential. however, the
splitting itself causes other problems:

1) since dm-crypt relies on the block layer zone write plugging to
   handle zone append emulation using regular write operations, the
   reminder of a split write bio will always be plugged into the target
   zone write plugged. once the on-going write bio finishes, this
   reminder bio is unplugged and issued from the zone write plug work.
   if this reminder bio itself needs to be split, the reminder will be
   re-issued and plugged again, but that causes a call to a
   blk_queue_enter(), which may block if a queue freeze operation was
   initiated. this results in a deadlock as dm submission still holds
   bios that the queue freeze side is waiting for.

2) dm-crypt relies on the emulation done by the block layer using
   regular write operations for processing zone append operations. this
   still requires to properly return the written sector as the bio
   sector of the original bio. however, this can be done correctly only
   and only if there is a single clone bio used for processing the
   original zone append operation issued by the user. if the size of a
   zone append operation is larger than dm-crypt max_write_size, then
   the orginal bio will be split and processed as a chain of regular
   write operations. such chaining result in an incorrect written sector
   being returned to the zone append issuer using the original bio
   sector.  this in turn results in file system data corruptions using
   xfs or btrfs.

fix this by modifying get_max_request_size() to always return the size
of the bio to avoid it being split with dm_accpet_partial_bio() in
crypt_map(). get_max_request_size() is renamed to
get_max_request_sectors() to clarify the unit of the value returned
and its interface is changed to take a struct dm_target pointer and a
pointer to the struct bio being processed. in addition to this change,
to ensure that crypt_alloc_buffer() works correctly, set the dm-crypt
device max_hw_sectors limit to be at most
bio_max_vecs << page_sectors_shift (1 mb with a 4kb page architecture).
this forces dm core to split write bios before passing them to
crypt_map(), and thus guaranteeing that dm-crypt can always accept an
entire write bio without needing to split it.

this change does not have any effect on the read path of dm-crypt. read
operations can still be split and the bio fragments processed in
parallel. there is also no impact on the performance of the write path
given that all zone write bios were already processed inline instead of
in parallel.

this change also does not affect in any way regular dm-crypt block
devices.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39791" target="_blank">CVE-2025-39791</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:45 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

dm: dm-crypt: Do not partially accept write BIOs with zoned targets

Read and write operations issued to a dm-crypt target may be split
according to the dm-crypt internal limits defined by the max_read_size
and max_write_size module parameters (default is 128 KB). The intent is
to improve processing time of large BIOs by splitting them into smaller
operations that can be parallelized on different CPUs.

For zoned dm-crypt targets, this BIO splitting is still done but without
the parallel execution to ensure that the issuing order of write
operations to the underlying devices remains sequential. However, the
splitting itself causes other problems:

1) Since dm-crypt relies on the block layer zone write plugging to
   handle zone append emulation using regular write operations, the
   reminder of a split write BIO will always be plugged into the target
   zone write plugged. Once the on-going write BIO finishes, this
   reminder BIO is unplugged and issued from the zone write plug work.
   If this reminder BIO itself needs to be split, the reminder will be
   re-issued and plugged again, but that causes a call to a
   blk_queue_enter(), which may block if a queue freeze operation was
   initiated. This results in a deadlock as DM submission still holds
   BIOs that the queue freeze side is waiting for.

2) dm-crypt relies on the emulation done by the block layer using
   regular write operations for processing zone append operations. This
   still requires to properly return the written sector as the BIO
   sector of the original BIO. However, this can be done correctly only
   and only if there is a single clone BIO used for processing the
   original zone append operation issued by the user. If the size of a
   zone append operation is larger than dm-crypt max_write_size, then
   the orginal BIO will be split and processed as a chain of regular
   write operations. Such chaining result in an incorrect written sector
   being returned to the zone append issuer using the original BIO
   sector.  This in turn results in file system data corruptions using
   xfs or btrfs.

Fix this by modifying get_max_request_size() to always return the size
of the BIO to avoid it being split with dm_accpet_partial_bio() in
crypt_map(). get_max_request_size() is renamed to
get_max_request_sectors() to clarify the unit of the value returned
and its interface is changed to take a struct dm_target pointer and a
pointer to the struct bio being processed. In addition to this change,
to ensure that crypt_alloc_buffer() works correctly, set the dm-crypt
device max_hw_sectors limit to be at most
BIO_MAX_VECS << PAGE_SECTORS_SHIFT (1 MB with a 4KB page architecture).
This forces DM core to split write BIOs before passing them to
crypt_map(), and thus guaranteeing that dm-crypt can always accept an
entire write BIO without needing to split it.

This change does not have any effect on the read path of dm-crypt. Read
operations can still be split and the BIO fragments processed in
parallel. There is also no impact on the performance of the write path
given that all zone write BIOs were already processed inline instead of
in parallel.

This change also does not affect in any way regular dm-crypt block
devices.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39790" data-description="in the linux kernel, the following vulnerability has been resolved:

bus: mhi: host: detect events pointing to unexpected tres

when a remote device sends a completion event to the host, it contains a
pointer to the consumed tre. the host uses this pointer to process all of
the tres between it and the host's local copy of the ring's read pointer.
this works when processing completion for chained transactions, but can
lead to nasty results if the device sends an event for a single-element
transaction with a read pointer that is multiple elements ahead of the
host's read pointer.

for instance, if the host accesses an event ring while the device is
updating it, the pointer inside of the event might still point to an old
tre. if the host uses the channel's xfer_cb() to directly free the buffer
pointed to by the tre, the buffer will be double-freed.

this behavior was observed on an ep that used upstream ep stack without
'commit 6f18d174b73d ("bus: mhi: ep: update read pointer only after buffer
is written")'. where the device updated the events ring pointer before
updating the event contents, so it left a window where the host was able to
access the stale data the event pointed to, before the device had the
chance to update them. the usual pattern was that the host received an
event pointing to a tre that is not immediately after the last processed
one, so it got treated as if it was a chained transaction, processing all
of the tres in between the two read pointers.

this commit aims to harden the host by ensuring transactions where the
event points to a tre that isn't local_rp + 1 are chained.

[mani: added stable tag and reworded commit message]">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39790" target="_blank">CVE-2025-39790</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:45 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

bus: mhi: host: Detect events pointing to unexpected TREs

When a remote device sends a completion event to the host, it contains a
pointer to the consumed TRE. The host uses this pointer to process all of
the TREs between it and the host's local copy of the ring's read pointer.
This works when processing completion for chained transactions, but can
lead to nasty results if the device sends an event for a single-element
transaction with a read pointer that is multiple elements ahead of the
host's read pointer.

For instance, if the host accesses an event ring while the device is
updating it, the pointer inside of the event might still point to an old
TRE. If the host uses the channel's xfer_cb() to directly free the buffer
pointed to by the TRE, the buffer will be double-freed.

This behavior was observed on an ep that used upstream EP stack without
'commit 6f18d174b73d ("bus: mhi: ep: Update read pointer only after buffer
is written")'. Where the device updated the events ring pointer before
updating the event contents, so it left a window where the host was able to
access the stale data the event pointed to, before the device had the
chance to update them. The usual pattern was that the host received an
event pointing to a TRE that is not immediately after the last processed
one, so it got treated as if it was a chained transaction, processing all
of the TREs in between the two read pointers.

This commit aims to harden the host by ensuring transactions where the
event points to a TRE that isn't local_rp + 1 are chained.

[mani: added stable tag and reworded commit message]</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39789" data-description="in the linux kernel, the following vulnerability has been resolved:

crypto: x86/aegis - add missing error checks

the skcipher_walk functions can allocate memory and can fail, so
checking for errors is necessary.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39789" target="_blank">CVE-2025-39789</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:45 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

crypto: x86/aegis - Add missing error checks

The skcipher_walk functions can allocate memory and can fail, so
checking for errors is necessary.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39788" data-description="in the linux kernel, the following vulnerability has been resolved:

scsi: ufs: exynos: fix programming of hci_utrl_nexus_type

on google gs101, the number of utp transfer request slots (nutrs) is 32,
and in this case the driver ends up programming the utrl_nexus_type
incorrectly as 0.

this is because the left hand side of the shift is 1, which is of type
int, i.e. 31 bits wide. shifting by more than that width results in
undefined behaviour.

fix this by switching to the bit() macro, which applies correct type
casting as required. this ensures the correct value is written to
utrl_nexus_type (0xffffffff on gs101), and it also fixes a ubsan shift
warning:

    ubsan: shift-out-of-bounds in drivers/ufs/host/ufs-exynos.c:1113:21
    shift exponent 32 is too large for 32-bit type 'int'

for consistency, apply the same change to the nutmrs / utmrl_nexus_type
write.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39788" target="_blank">CVE-2025-39788</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:45 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

scsi: ufs: exynos: Fix programming of HCI_UTRL_NEXUS_TYPE

On Google gs101, the number of UTP transfer request slots (nutrs) is 32,
and in this case the driver ends up programming the UTRL_NEXUS_TYPE
incorrectly as 0.

This is because the left hand side of the shift is 1, which is of type
int, i.e. 31 bits wide. Shifting by more than that width results in
undefined behaviour.

Fix this by switching to the BIT() macro, which applies correct type
casting as required. This ensures the correct value is written to
UTRL_NEXUS_TYPE (0xffffffff on gs101), and it also fixes a UBSAN shift
warning:

    UBSAN: shift-out-of-bounds in drivers/ufs/host/ufs-exynos.c:1113:21
    shift exponent 32 is too large for 32-bit type 'int'

For consistency, apply the same change to the nutmrs / UTMRL_NEXUS_TYPE
write.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39787" data-description="in the linux kernel, the following vulnerability has been resolved:

soc: qcom: mdt_loader: ensure we don't read past the elf header

when the mdt loader is used in remoteproc, the elf header is sanitized
beforehand, but that's not necessary the case for other clients.

validate the size of the firmware buffer to ensure that we don't read
past the end as we iterate over the header. e_phentsize and e_shentsize
are validated as well, to ensure that the assumptions about step size in
the traversal are valid.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39787" target="_blank">CVE-2025-39787</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

soc: qcom: mdt_loader: Ensure we don't read past the ELF header

When the MDT loader is used in remoteproc, the ELF header is sanitized
beforehand, but that's not necessary the case for other clients.

Validate the size of the firmware buffer to ensure that we don't read
past the end as we iterate over the header. e_phentsize and e_shentsize
are validated as well, to ensure that the assumptions about step size in
the traversal are valid.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39786" data-description="in the linux kernel, the following vulnerability has been resolved:

iio: adc: ad7173: fix channels index for syscalib_mode

fix the index used to look up the channel when accessing the
syscalib_mode attribute. the address field is a 0-based index (same
as scan_index) that it used to access the channel in the
ad7173_channels array throughout the driver. the channels field, on
the other hand, may not match the address field depending on the
channel configuration specified in the device tree and could result
in an out-of-bounds access.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39786" target="_blank">CVE-2025-39786</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

iio: adc: ad7173: fix channels index for syscalib_mode

Fix the index used to look up the channel when accessing the
syscalib_mode attribute. The address field is a 0-based index (same
as scan_index) that it used to access the channel in the
ad7173_channels array throughout the driver. The channels field, on
the other hand, may not match the address field depending on the
channel configuration specified in the device tree and could result
in an out-of-bounds access.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39785" data-description="in the linux kernel, the following vulnerability has been resolved:

drm/hisilicon/hibmc: fix irq_request()'s irq name variable is local

the local variable is passed in request_irq (), and there will be use
after free problem, which will make request_irq failed. using the global
irq name instead of it to fix.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39785" target="_blank">CVE-2025-39785</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

drm/hisilicon/hibmc: fix irq_request()'s irq name variable is local

The local variable is passed in request_irq (), and there will be use
after free problem, which will make request_irq failed. Using the global
irq name instead of it to fix.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39784" data-description="in the linux kernel, the following vulnerability has been resolved:

pci: fix link speed calculation on retrain failure

when pcie_failed_link_retrain() fails to retrain, it tries to revert to the
previous link speed.  however it calculates that speed from the link
control 2 register without masking out non-speed bits first.

pcie_lnkctl2_tls2speed() converts such incorrect values to
pci_speed_unknown (0xff), which in turn causes a warn splat in
pcie_set_target_speed():

  pci 0000:00:01.1: [1022:14ed] type 01 class 0x060400 pcie root port
  pci 0000:00:01.1: broken device, retraining non-functional downstream link at 2.5gt/s
  pci 0000:00:01.1: retraining failed
  warning: cpu: 1 pid: 1 at drivers/pci/pcie/bwctrl.c:168 pcie_set_target_speed
  rdx: 0000000000000001 rsi: 00000000000000ff rdi: ffff9acd82efa000
  pcie_failed_link_retrain
  pci_device_add
  pci_scan_single_device

mask out the non-speed bits in pcie_lnkctl2_tls2speed() and
pcie_lnkcap_sls2speed() so they don't incorrectly return pci_speed_unknown.

[bhelgaas: commit log, add details from https://lore.kernel.org/r/1c92ef6bcb314ee6977839b46b393282e4f52e74.1750684771.git.lukas@wunner.de]">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39784" target="_blank">CVE-2025-39784</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

PCI: Fix link speed calculation on retrain failure

When pcie_failed_link_retrain() fails to retrain, it tries to revert to the
previous link speed.  However it calculates that speed from the Link
Control 2 register without masking out non-speed bits first.

PCIE_LNKCTL2_TLS2SPEED() converts such incorrect values to
PCI_SPEED_UNKNOWN (0xff), which in turn causes a WARN splat in
pcie_set_target_speed():

  pci 0000:00:01.1: [1022:14ed] type 01 class 0x060400 PCIe Root Port
  pci 0000:00:01.1: broken device, retraining non-functional downstream link at 2.5GT/s
  pci 0000:00:01.1: retraining failed
  WARNING: CPU: 1 PID: 1 at drivers/pci/pcie/bwctrl.c:168 pcie_set_target_speed
  RDX: 0000000000000001 RSI: 00000000000000ff RDI: ffff9acd82efa000
  pcie_failed_link_retrain
  pci_device_add
  pci_scan_single_device

Mask out the non-speed bits in PCIE_LNKCTL2_TLS2SPEED() and
PCIE_LNKCAP_SLS2SPEED() so they don't incorrectly return PCI_SPEED_UNKNOWN.

[bhelgaas: commit log, add details from https://lore.kernel.org/r/1c92ef6bcb314ee6977839b46b393282e4f52e74.1750684771.git.lukas@wunner.de]</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39783" data-description="in the linux kernel, the following vulnerability has been resolved:

pci: endpoint: fix configfs group list head handling

doing a list_del() on the epf_group field of struct pci_epf_driver in
pci_epf_remove_cfs() is not correct as this field is a list head, not
a list entry. this list_del() call triggers a kasan warning when an
endpoint function driver which has a configfs attribute group is torn
down:

==================================================================
bug: kasan: slab-use-after-free in pci_epf_remove_cfs+0x17c/0x198
write of size 8 at addr ffff00010f4a0d80 by task rmmod/319

cpu: 3 uid: 0 pid: 319 comm: rmmod not tainted 6.16.0-rc2 #1 none
hardware name: radxa rock 5b (dt)
call trace:
show_stack+0x2c/0x84 (c)
dump_stack_lvl+0x70/0x98
print_report+0x17c/0x538
kasan_report+0xb8/0x190
__asan_report_store8_noabort+0x20/0x2c
pci_epf_remove_cfs+0x17c/0x198
pci_epf_unregister_driver+0x18/0x30
nvmet_pci_epf_cleanup_module+0x24/0x30 [nvmet_pci_epf]
__arm64_sys_delete_module+0x264/0x424
invoke_syscall+0x70/0x260
el0_svc_common.constprop.0+0xac/0x230
do_el0_svc+0x40/0x58
el0_svc+0x48/0xdc
el0t_64_sync_handler+0x10c/0x138
el0t_64_sync+0x198/0x19c
...

remove this incorrect list_del() call from pci_epf_remove_cfs().">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39783" target="_blank">CVE-2025-39783</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

PCI: endpoint: Fix configfs group list head handling

Doing a list_del() on the epf_group field of struct pci_epf_driver in
pci_epf_remove_cfs() is not correct as this field is a list head, not
a list entry. This list_del() call triggers a KASAN warning when an
endpoint function driver which has a configfs attribute group is torn
down:

==================================================================
BUG: KASAN: slab-use-after-free in pci_epf_remove_cfs+0x17c/0x198
Write of size 8 at addr ffff00010f4a0d80 by task rmmod/319

CPU: 3 UID: 0 PID: 319 Comm: rmmod Not tainted 6.16.0-rc2 #1 NONE
Hardware name: Radxa ROCK 5B (DT)
Call trace:
show_stack+0x2c/0x84 (C)
dump_stack_lvl+0x70/0x98
print_report+0x17c/0x538
kasan_report+0xb8/0x190
__asan_report_store8_noabort+0x20/0x2c
pci_epf_remove_cfs+0x17c/0x198
pci_epf_unregister_driver+0x18/0x30
nvmet_pci_epf_cleanup_module+0x24/0x30 [nvmet_pci_epf]
__arm64_sys_delete_module+0x264/0x424
invoke_syscall+0x70/0x260
el0_svc_common.constprop.0+0xac/0x230
do_el0_svc+0x40/0x58
el0_svc+0x48/0xdc
el0t_64_sync_handler+0x10c/0x138
el0t_64_sync+0x198/0x19c
...

Remove this incorrect list_del() call from pci_epf_remove_cfs().</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39782" data-description="in the linux kernel, the following vulnerability has been resolved:

jbd2: prevent softlockup in jbd2_log_do_checkpoint()

both jbd2_log_do_checkpoint() and jbd2_journal_shrink_checkpoint_list()
periodically release j_list_lock after processing a batch of buffers to
avoid long hold times on the j_list_lock. however, since both functions
contend for j_list_lock, the combined time spent waiting and processing
can be significant.

jbd2_journal_shrink_checkpoint_list() explicitly calls cond_resched() when
need_resched() is true to avoid softlockups during prolonged operations.
but jbd2_log_do_checkpoint() only exits its loop when need_resched() is
true, relying on potentially sleeping functions like __flush_batch() or
wait_on_buffer() to trigger rescheduling. if those functions do not sleep,
the kernel may hit a softlockup.

watchdog: bug: soft lockup - cpu#3 stuck for 156s! [kworker/u129:2:373]
cpu: 3 pid: 373 comm: kworker/u129:2 kdump: loaded not tainted 6.6.0+ #10
hardware name: huawei taishan 2280 /bc11spcd, bios 1.27 06/13/2017
workqueue: writeback wb_workfn (flush-7:2)
pstate: 20000005 (nzcv daif -pan -uao -tco -dit -ssbs btype=--)
pc : native_queued_spin_lock_slowpath+0x358/0x418
lr : jbd2_log_do_checkpoint+0x31c/0x438 [jbd2]
call trace:
 native_queued_spin_lock_slowpath+0x358/0x418
 jbd2_log_do_checkpoint+0x31c/0x438 [jbd2]
 __jbd2_log_wait_for_space+0xfc/0x2f8 [jbd2]
 add_transaction_credits+0x3bc/0x418 [jbd2]
 start_this_handle+0xf8/0x560 [jbd2]
 jbd2__journal_start+0x118/0x228 [jbd2]
 __ext4_journal_start_sb+0x110/0x188 [ext4]
 ext4_do_writepages+0x3dc/0x740 [ext4]
 ext4_writepages+0xa4/0x190 [ext4]
 do_writepages+0x94/0x228
 __writeback_single_inode+0x48/0x318
 writeback_sb_inodes+0x204/0x590
 __writeback_inodes_wb+0x54/0xf8
 wb_writeback+0x2cc/0x3d8
 wb_do_writeback+0x2e0/0x2f8
 wb_workfn+0x80/0x2a8
 process_one_work+0x178/0x3e8
 worker_thread+0x234/0x3b8
 kthread+0xf0/0x108
 ret_from_fork+0x10/0x20

so explicitly call cond_resched() in jbd2_log_do_checkpoint() to avoid
softlockup.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39782" target="_blank">CVE-2025-39782</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

jbd2: prevent softlockup in jbd2_log_do_checkpoint()

Both jbd2_log_do_checkpoint() and jbd2_journal_shrink_checkpoint_list()
periodically release j_list_lock after processing a batch of buffers to
avoid long hold times on the j_list_lock. However, since both functions
contend for j_list_lock, the combined time spent waiting and processing
can be significant.

jbd2_journal_shrink_checkpoint_list() explicitly calls cond_resched() when
need_resched() is true to avoid softlockups during prolonged operations.
But jbd2_log_do_checkpoint() only exits its loop when need_resched() is
true, relying on potentially sleeping functions like __flush_batch() or
wait_on_buffer() to trigger rescheduling. If those functions do not sleep,
the kernel may hit a softlockup.

watchdog: BUG: soft lockup - CPU#3 stuck for 156s! [kworker/u129:2:373]
CPU: 3 PID: 373 Comm: kworker/u129:2 Kdump: loaded Not tainted 6.6.0+ #10
Hardware name: Huawei TaiShan 2280 /BC11SPCD, BIOS 1.27 06/13/2017
Workqueue: writeback wb_workfn (flush-7:2)
pstate: 20000005 (nzCv daif -PAN -UAO -TCO -DIT -SSBS BTYPE=--)
pc : native_queued_spin_lock_slowpath+0x358/0x418
lr : jbd2_log_do_checkpoint+0x31c/0x438 [jbd2]
Call trace:
 native_queued_spin_lock_slowpath+0x358/0x418
 jbd2_log_do_checkpoint+0x31c/0x438 [jbd2]
 __jbd2_log_wait_for_space+0xfc/0x2f8 [jbd2]
 add_transaction_credits+0x3bc/0x418 [jbd2]
 start_this_handle+0xf8/0x560 [jbd2]
 jbd2__journal_start+0x118/0x228 [jbd2]
 __ext4_journal_start_sb+0x110/0x188 [ext4]
 ext4_do_writepages+0x3dc/0x740 [ext4]
 ext4_writepages+0xa4/0x190 [ext4]
 do_writepages+0x94/0x228
 __writeback_single_inode+0x48/0x318
 writeback_sb_inodes+0x204/0x590
 __writeback_inodes_wb+0x54/0xf8
 wb_writeback+0x2cc/0x3d8
 wb_do_writeback+0x2e0/0x2f8
 wb_workfn+0x80/0x2a8
 process_one_work+0x178/0x3e8
 worker_thread+0x234/0x3b8
 kthread+0xf0/0x108
 ret_from_fork+0x10/0x20

So explicitly call cond_resched() in jbd2_log_do_checkpoint() to avoid
softlockup.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39781" data-description="in the linux kernel, the following vulnerability has been resolved:

parisc: drop warn_on_once() from flush_cache_vmap

i have observed warning to occassionally trigger.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39781" target="_blank">CVE-2025-39781</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:44 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

parisc: Drop WARN_ON_ONCE() from flush_cache_vmap

I have observed warning to occassionally trigger.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39780" data-description="in the linux kernel, the following vulnerability has been resolved:

sched/ext: fix invalid task state transitions on class switch

when enabling a sched_ext scheduler, we may trigger invalid task state
transitions, resulting in warnings like the following (which can be
easily reproduced by running the hotplug selftest in a loop):

 sched_ext: invalid task state transition 0 -> 3 for fish[770]
 warning: cpu: 18 pid: 787 at kernel/sched/ext.c:3862 scx_set_task_state+0x7c/0xc0
 ...
 rip: 0010:scx_set_task_state+0x7c/0xc0
 ...
 call trace:
  <task>
  scx_enable_task+0x11f/0x2e0
  switching_to_scx+0x24/0x110
  scx_enable.isra.0+0xd14/0x13d0
  bpf_struct_ops_link_create+0x136/0x1a0
  __sys_bpf+0x1edd/0x2c30
  __x64_sys_bpf+0x21/0x30
  do_syscall_64+0xbb/0x370
  entry_syscall_64_after_hwframe+0x77/0x7f

this happens because we skip initialization for tasks that are already
dead (with their usage counter set to zero), but we don't exclude them
during the scheduling class transition phase.

fix this by also skipping dead tasks during class swiching, preventing
invalid task state transitions.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39780" target="_blank">CVE-2025-39780</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:43 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

sched/ext: Fix invalid task state transitions on class switch

When enabling a sched_ext scheduler, we may trigger invalid task state
transitions, resulting in warnings like the following (which can be
easily reproduced by running the hotplug selftest in a loop):

 sched_ext: Invalid task state transition 0 -> 3 for fish[770]
 WARNING: CPU: 18 PID: 787 at kernel/sched/ext.c:3862 scx_set_task_state+0x7c/0xc0
 ...
 RIP: 0010:scx_set_task_state+0x7c/0xc0
 ...
 Call Trace:
  <TASK>
  scx_enable_task+0x11f/0x2e0
  switching_to_scx+0x24/0x110
  scx_enable.isra.0+0xd14/0x13d0
  bpf_struct_ops_link_create+0x136/0x1a0
  __sys_bpf+0x1edd/0x2c30
  __x64_sys_bpf+0x21/0x30
  do_syscall_64+0xbb/0x370
  entry_SYSCALL_64_after_hwframe+0x77/0x7f

This happens because we skip initialization for tasks that are already
dead (with their usage counter set to zero), but we don't exclude them
during the scheduling class transition phase.

Fix this by also skipping dead tasks during class swiching, preventing
invalid task state transitions.</p>
                </div>
        
                <div class="cve-entry" data-cve-id="CVE-2025-39779" data-description="in the linux kernel, the following vulnerability has been resolved:

btrfs: subpage: keep towrite tag until folio is cleaned

btrfs_subpage_set_writeback() calls folio_start_writeback() the first time
a folio is written back, and it also clears the pagecache_tag_towrite tag
even if there are still dirty blocks in the folio. this can break ordering
guarantees, such as those required by btrfs_wait_ordered_extents().

that ordering breakage leads to a real failure. for example, running
generic/464 on a zoned setup will hit the following assert. this happens
because the broken ordering fails to flush existing dirty pages before the
file size is truncated.

  assertion failed: !list_empty(&ordered->list) :: 0, in fs/btrfs/zoned.c:1899
  ------------[ cut here ]------------
  kernel bug at fs/btrfs/zoned.c:1899!
  oops: invalid opcode: 0000 [#1] smp nopti
  cpu: 2 uid: 0 pid: 1906169 comm: kworker/u130:2 kdump: loaded not tainted 6.16.0-rc6-btrfs-zns+ #554 preempt(voluntary)
  hardware name: supermicro super server/h12ssl-nt, bios 2.0 02/22/2021
  workqueue: btrfs-endio-write btrfs_work_helper [btrfs]
  rip: 0010:btrfs_finish_ordered_zoned.cold+0x50/0x52 [btrfs]
  rsp: 0018:ffffc9002efdbd60 eflags: 00010246
  rax: 000000000000004c rbx: ffff88811923c4e0 rcx: 0000000000000000
  rdx: 0000000000000000 rsi: ffffffff827e38b1 rdi: 00000000ffffffff
  rbp: ffff88810005d000 r08: 00000000ffffdfff r09: ffffffff831051c8
  r10: ffffffff83055220 r11: 0000000000000000 r12: ffff8881c2458c00
  r13: ffff88811923c540 r14: ffff88811923c5e8 r15: ffff8881c1bd9680
  fs:  0000000000000000(0000) gs:ffff88a04acd0000(0000) knlgs:0000000000000000
  cs:  0010 ds: 0000 es: 0000 cr0: 0000000080050033
  cr2: 00007f907c7a918c cr3: 0000000004024000 cr4: 0000000000350ef0
  call trace:
   <task>
   ? srso_return_thunk+0x5/0x5f
   btrfs_finish_ordered_io+0x4a/0x60 [btrfs]
   btrfs_work_helper+0xf9/0x490 [btrfs]
   process_one_work+0x204/0x590
   ? srso_return_thunk+0x5/0x5f
   worker_thread+0x1d6/0x3d0
   ? __pfx_worker_thread+0x10/0x10
   kthread+0x118/0x230
   ? __pfx_kthread+0x10/0x10
   ret_from_fork+0x205/0x260
   ? __pfx_kthread+0x10/0x10
   ret_from_fork_asm+0x1a/0x30
   </task>

consider process a calling writepages() with wb_sync_none. in zoned mode or
for compressed writes, it locks several folios for delalloc and starts
writing them out. let's call the last locked folio folio x. suppose the
write range only partially covers folio x, leaving some pages dirty.
process a calls btrfs_subpage_set_writeback() when building a bio. this
function call clears the towrite tag of folio x, whose size = 8k and
the block size = 4k. it is following state.

   0     4k    8k
   |/////|/////|  (flag: dirty, tag: dirty)
   <-----> process a will write this range.

now suppose process b concurrently calls writepages() with wb_sync_all. it
calls tag_pages_for_writeback() to tag dirty folios with
pagecache_tag_towrite. since folio x is still dirty, it gets tagged. then,
b collects tagged folios using filemap_get_folios_tag() and must wait for
folio x to be written before returning from writepages().

   0     4k    8k
   |/////|/////|  (flag: dirty, tag: dirty|towrite)

however, between tagging and collecting, process a may call
btrfs_subpage_set_writeback() and clear folio x's towrite tag.
   0     4k    8k
   |     |/////|  (flag: dirty|writeback, tag: dirty)

as a result, process b won't see folio x in its batch, and returns without
waiting for it. this breaks the wb_sync_all ordering requirement.

fix this by using btrfs_subpage_set_writeback_keepwrite(), which retains
the towrite tag. we now manually clear the tag only after the folio becomes
clean, via the xas operation.">
                    <h2><a class="contact-button" href="https://nvd.nist.gov/vuln/detail/CVE-2025-39779" target="_blank">CVE-2025-39779</a></h2>
                    <p><span class="feed-label">Published:</span> 2025-09-11 12:15:43 CDT</p>
                    <p><span class="feed-label">Severity:</span> <span class="status-offline">N/A</span></p>
                    <p><span class="feed-label">CVSS Score:</span> N/A</p>
                    <p>In the Linux kernel, the following vulnerability has been resolved:

btrfs: subpage: keep TOWRITE tag until folio is cleaned

btrfs_subpage_set_writeback() calls folio_start_writeback() the first time
a folio is written back, and it also clears the PAGECACHE_TAG_TOWRITE tag
even if there are still dirty blocks in the folio. This can break ordering
guarantees, such as those required by btrfs_wait_ordered_extents().

That ordering breakage leads to a real failure. For example, running
generic/464 on a zoned setup will hit the following ASSERT. This happens
because the broken ordering fails to flush existing dirty pages before the
file size is truncated.

  assertion failed: !list_empty(&ordered->list) :: 0, in fs/btrfs/zoned.c:1899
  ------------[ cut here ]------------
  kernel BUG at fs/btrfs/zoned.c:1899!
  Oops: invalid opcode: 0000 [#1] SMP NOPTI
  CPU: 2 UID: 0 PID: 1906169 Comm: kworker/u130:2 Kdump: loaded Not tainted 6.16.0-rc6-BTRFS-ZNS+ #554 PREEMPT(voluntary)
  Hardware name: Supermicro Super Server/H12SSL-NT, BIOS 2.0 02/22/2021
  Workqueue: btrfs-endio-write btrfs_work_helper [btrfs]
  RIP: 0010:btrfs_finish_ordered_zoned.cold+0x50/0x52 [btrfs]
  RSP: 0018:ffffc9002efdbd60 EFLAGS: 00010246
  RAX: 000000000000004c RBX: ffff88811923c4e0 RCX: 0000000000000000
  RDX: 0000000000000000 RSI: ffffffff827e38b1 RDI: 00000000ffffffff
  RBP: ffff88810005d000 R08: 00000000ffffdfff R09: ffffffff831051c8
  R10: ffffffff83055220 R11: 0000000000000000 R12: ffff8881c2458c00
  R13: ffff88811923c540 R14: ffff88811923c5e8 R15: ffff8881c1bd9680
  FS:  0000000000000000(0000) GS:ffff88a04acd0000(0000) knlGS:0000000000000000
  CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
  CR2: 00007f907c7a918c CR3: 0000000004024000 CR4: 0000000000350ef0
  Call Trace:
   <TASK>
   ? srso_return_thunk+0x5/0x5f
   btrfs_finish_ordered_io+0x4a/0x60 [btrfs]
   btrfs_work_helper+0xf9/0x490 [btrfs]
   process_one_work+0x204/0x590
   ? srso_return_thunk+0x5/0x5f
   worker_thread+0x1d6/0x3d0
   ? __pfx_worker_thread+0x10/0x10
   kthread+0x118/0x230
   ? __pfx_kthread+0x10/0x10
   ret_from_fork+0x205/0x260
   ? __pfx_kthread+0x10/0x10
   ret_from_fork_asm+0x1a/0x30
   </TASK>

Consider process A calling writepages() with WB_SYNC_NONE. In zoned mode or
for compressed writes, it locks several folios for delalloc and starts
writing them out. Let's call the last locked folio folio X. Suppose the
write range only partially covers folio X, leaving some pages dirty.
Process A calls btrfs_subpage_set_writeback() when building a bio. This
function call clears the TOWRITE tag of folio X, whose size = 8K and
the block size = 4K. It is following state.

   0     4K    8K
   |/////|/////|  (flag: DIRTY, tag: DIRTY)
   <-----> Process A will write this range.

Now suppose process B concurrently calls writepages() with WB_SYNC_ALL. It
calls tag_pages_for_writeback() to tag dirty folios with
PAGECACHE_TAG_TOWRITE. Since folio X is still dirty, it gets tagged. Then,
B collects tagged folios using filemap_get_folios_tag() and must wait for
folio X to be written before returning from writepages().

   0     4K    8K
   |/////|/////|  (flag: DIRTY, tag: DIRTY|TOWRITE)

However, between tagging and collecting, process A may call
btrfs_subpage_set_writeback() and clear folio X's TOWRITE tag.
   0     4K    8K
   |     |/////|  (flag: DIRTY|WRITEBACK, tag: DIRTY)

As a result, process B won't see folio X in its batch, and returns without
waiting for it. This breaks the WB_SYNC_ALL ordering requirement.

Fix this by using btrfs_subpage_set_writeback_keepwrite(), which retains
the TOWRITE tag. We now manually clear the tag only after the folio becomes
clean, via the xas operation.</p>
                </div>
        
            </div>
        </div>

        <footer class="footer">
            <p>© 2025 dotne1 - Cybersecurity Portfolio</p>
        </footer>

        <script>
            function searchCVEs() {
                const input = document.getElementById('searchInput').value.toLowerCase();
                const cveEntries = document.getElementsByClassName('cve-entry');
                for (let i = 0; i < cveEntries.length; i++) {
                    const cveId = cveEntries[i].getAttribute('data-cve-id').toLowerCase();
                    const description = cveEntries[i].getAttribute('data-description');
                    if (cveId.includes(input) || description.includes(input)) {
                        cveEntries[i].style.display = '';
                    } else {
                        cveEntries[i].style.display = 'none';
                    }
                }
            }
        </script>
    </body>
    </html>
    